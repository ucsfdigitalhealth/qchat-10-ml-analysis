{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":4066903,"sourceType":"datasetVersion","datasetId":2343965},{"sourceId":7960772,"sourceType":"datasetVersion","datasetId":4682968},{"sourceId":10841523,"sourceType":"datasetVersion","datasetId":38367}],"dockerImageVersionId":30698,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Imports and Function Definitions","metadata":{}},{"cell_type":"markdown","source":"## Imports","metadata":{}},{"cell_type":"code","source":"'''\nTrain and test various models on three separate QCHAT-10 data sets; perform feature selection analysis\nAuthor: Lydia Sollis\nDate: Mar 25 2024\n'''\n\n# Install necessary packages not included in the environment\n!pip install pyreadstat\n\n# Standard libraries for data manipulation and mathematical operations\nimport os\nimport math\nimport numpy as np \nimport pandas as pd\n\n# Data loading and transformation\nimport pyreadstat\nfrom scipy.io import arff\n\n# Data visualization\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n# Preprocessing tools from scikit-learn\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV, cross_val_score, StratifiedKFold, cross_validate, cross_val_predict\n\n# Machine learning models\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.svm import SVC\nfrom xgboost import XGBClassifier\n\n# Feature selection tools\nfrom sklearn.feature_selection import RFE, SequentialFeatureSelector\n\n# Metrics for model evaluation\nimport sklearn.metrics as metrics\nfrom sklearn.metrics import (\n    accuracy_score, precision_score, recall_score, roc_auc_score, \n    confusion_matrix, classification_report, roc_curve, make_scorer,\n    ConfusionMatrixDisplay, balanced_accuracy_score\n)\n\n# Configure pandas to raise an exception instead of silently downcasting types\npd.set_option('future.no_silent_downcasting', True) \n\n# Function to list all files under the input directory in a Kaggle environment\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2025-10-06T20:13:48.570514Z","iopub.execute_input":"2025-10-06T20:13:48.570903Z","iopub.status.idle":"2025-10-06T20:14:04.299472Z","shell.execute_reply.started":"2025-10-06T20:13:48.570875Z","shell.execute_reply":"2025-10-06T20:14:04.298285Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Functions","metadata":{}},{"cell_type":"code","source":"# Custom scorer for specificity\ndef specificity_score(y_true, y_pred):\n    cm = confusion_matrix(y_true, y_pred)\n    tn, fp, fn, tp = cm.ravel()\n    return tn / (tn + fp)\n\n# Function to ensure columns of different datasets are in the same order prior to train/test\ndef check_and_reorder_columns(df_source, df_target):\n    if (df_source.columns == df_target.columns).all():\n        print(\"Columns are the same.\")\n        return df_target\n    else:\n        print(\"Columns are not the same. Reordering...\")\n        return df_target[df_source.columns]","metadata":{"execution":{"iopub.status.busy":"2025-10-06T20:14:18.952118Z","iopub.execute_input":"2025-10-06T20:14:18.952658Z","iopub.status.idle":"2025-10-06T20:14:18.960268Z","shell.execute_reply.started":"2025-10-06T20:14:18.952618Z","shell.execute_reply":"2025-10-06T20:14:18.958891Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Load / Clean Data","metadata":{}},{"cell_type":"markdown","source":"## New Zealand Dataset","metadata":{}},{"cell_type":"code","source":"# Load file\npath = '/kaggle/input/autism-screening-for-toddlers/Toddler Autism dataset July 2018.csv'\ndata = pd.read_csv(path)\n# data, meta = arff.loadarff(path)\n\n# Convert the data to a Pandas DataFrame\ndf = pd.DataFrame(data)\n\n# If the data contains byte strings, convert them to regular strings\ndf = df.map(lambda x: x.decode('utf-8') if isinstance(x, bytes) else x)\n\n# Check the shape of the DataFrame before dropping duplicates\nprint(\"Shape of DataFrame before dropping duplicates:\", df.shape)\n\n# Drop duplicate rows\ndf.drop_duplicates(inplace=True)\n\n# Check the shape of the DataFrame after dropping duplicates\nprint(\"Shape of DataFrame after dropping duplicates:\", df.shape)\n\nprint(df.head())\nprint(df.describe())\nprint(df.info())\n\n# Rename misspelled / unclear columns\n# family_pdd = direct family member with pervasive developmental disorder\n# Five disorders are identified under the category of pervasive developmental disorders: (1) autistic disorder, (2) Rett's disorder, (3) childhood disintegrative disorder, (4) Asperger's syndrome, and (5) pervasive developmental disorder-not otherwise specified, or PDD-NOS (DSM-IV-TR, 2000).\n\ndf = df.rename(columns ={\n    'A1' : 'A1_Score',\n    'A2' : 'A2_Score',\n    'A3' : 'A3_Score',\n    'A4' : 'A4_Score',\n    'A5' : 'A5_Score',\n    'A6' : 'A6_Score',\n    'A7' : 'A7_Score',\n    'A8' : 'A8_Score',\n    'A9' : 'A9_Score',\n    'A10' : 'A10_Score',\n    'Age_Mons' : 'age_months',\n    'Class/ASD Traits ' : 'Class/ASD',\n    'Family_mem_with_ASD' : 'family_pdd',\n    'Jaundice' : 'jaundice',\n    'Ethnicity' : 'ethnicity',\n    'Qchat-10-Score' : 'result',\n    'Sex' : 'gender',\n    'Who completed the test' : 'relation'\n})\n\nlist(df.columns)","metadata":{"execution":{"iopub.status.busy":"2025-10-06T20:14:22.622703Z","iopub.execute_input":"2025-10-06T20:14:22.623129Z","iopub.status.idle":"2025-10-06T20:14:22.692072Z","shell.execute_reply.started":"2025-10-06T20:14:22.623097Z","shell.execute_reply":"2025-10-06T20:14:22.690846Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# print unique values for each column\nfor column in df.columns:\n    print(f\"{column}: {df[column].unique()}\")","metadata":{"execution":{"iopub.status.busy":"2025-10-06T20:14:29.190925Z","iopub.execute_input":"2025-10-06T20:14:29.191295Z","iopub.status.idle":"2025-10-06T20:14:29.205866Z","shell.execute_reply.started":"2025-10-06T20:14:29.191271Z","shell.execute_reply":"2025-10-06T20:14:29.204495Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# For a single column\nmean_val = df[\"age_months\"].mean()\nstd_val = df[\"age_months\"].std()\nmin_val = df[\"age_months\"].min()\nmax_val = df[\"age_months\"].max()\n\nprint(\"Mean:\", mean_val)\nprint(\"Standard Deviation:\", std_val)\nprint(\"Min:\", min_val)\nprint(\"Max:\", max_val)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-06T20:14:49.777398Z","iopub.execute_input":"2025-10-06T20:14:49.778231Z","iopub.status.idle":"2025-10-06T20:14:49.786877Z","shell.execute_reply.started":"2025-10-06T20:14:49.778189Z","shell.execute_reply":"2025-10-06T20:14:49.785786Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Replace text objects with boolean values\nfor column in ['A1_Score', 'A2_Score', 'A3_Score', 'A4_Score', 'A5_Score', 'A6_Score', 'A7_Score', 'A8_Score', 'A9_Score', 'A10_Score']:  # Add all your column names here\n    df[column] = df[column].replace({1: True, 0: False}).infer_objects()\n\nfor column in ['jaundice', 'family_pdd']:  # Add all your column names here\n    df[column] = df[column].replace({'yes': True, 'no': False}).infer_objects()\n\ndf['Class/ASD'] = df['Class/ASD'].replace({'Yes': 1, 'No': 0}).infer_objects()\n\n# Male gender represented as 'True' and female represented as 'False'\ndf['gender'] = df['gender'].replace({'m': True, 'f': False}).infer_objects()\n    \nfor column in df.columns:\n    print(f\"{column}: {df[column].unique()}\")\n\nprint(df.info())","metadata":{"execution":{"iopub.status.busy":"2024-06-26T20:38:13.304991Z","iopub.execute_input":"2024-06-26T20:38:13.305363Z","iopub.status.idle":"2024-06-26T20:38:13.347661Z","shell.execute_reply.started":"2024-06-26T20:38:13.305335Z","shell.execute_reply":"2024-06-26T20:38:13.346370Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Find count of null values\nprint(df.isnull().sum())\n\nsns.heatmap(df.isnull(), cbar=False)\n\n# Calculate the mean of the 'age_months' column\nage_months_mean = df['age_months'].mean()\n\n# Fill missing values in 'age_months' with the calculated mean\ndf['age_months'] = df['age_months'].fillna(age_months_mean)","metadata":{"execution":{"iopub.status.busy":"2024-06-26T20:38:13.349445Z","iopub.execute_input":"2024-06-26T20:38:13.349867Z","iopub.status.idle":"2024-06-26T20:38:13.974064Z","shell.execute_reply.started":"2024-06-26T20:38:13.349835Z","shell.execute_reply":"2024-06-26T20:38:13.972771Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# drop irrelevant columns / columns not in common between all datasets / \nprint(\"Current columns in the DataFrame:\", df.columns.tolist())\ndf_cleaned = df.drop(['Case_No', 'result', 'relation', 'ethnicity', 'jaundice'], axis=1)\ndf_cleaned.head()\n\n# Check the result\nprint(df_cleaned.shape)","metadata":{"execution":{"iopub.status.busy":"2024-06-26T20:38:13.975861Z","iopub.execute_input":"2024-06-26T20:38:13.976268Z","iopub.status.idle":"2024-06-26T20:38:13.988487Z","shell.execute_reply.started":"2024-06-26T20:38:13.976236Z","shell.execute_reply":"2024-06-26T20:38:13.987145Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\nfrom scipy import stats\n\n# Example dataframe\n# df = pd.DataFrame({\n#     \"age\": [...],\n#     \"result\": [...]\n# })\n\n# Split into groups\ngroup0 = df.loc[df[\"result\"] == 0, \"age_months\"]\ngroup1 = df.loc[df[\"result\"] == 1, \"age_months\"]\n\n# Independent samples t-test\nt_stat, p_val_ttest = stats.ttest_ind(group0, group1, equal_var=False)  # Welch’s t-test\nprint(\"T-test results:\")\nprint(\"t-statistic =\", t_stat, \"p-value =\", p_val_ttest)\n\n# Mann–Whitney U test (non-parametric)\nu_stat, p_val_mwu = stats.mannwhitneyu(group0, group1, alternative=\"two-sided\")\nprint(\"\\nMann-Whitney U test results:\")\nprint(\"U-statistic =\", u_stat, \"p-value =\", p_val_mwu)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-06T20:22:57.589334Z","iopub.execute_input":"2025-10-06T20:22:57.589788Z","iopub.status.idle":"2025-10-06T20:22:57.611007Z","shell.execute_reply.started":"2025-10-06T20:22:57.589749Z","shell.execute_reply":"2025-10-06T20:22:57.609342Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Iterate over each column in the DataFrame\nfor column in df_cleaned.columns:\n    # Check data type of the column\n    if df_cleaned[column].dtype == 'object':  # Categorical data\n        # Generate a bar plot for categorical data\n        df_cleaned[column].value_counts().plot(kind='bar', title=f'Distribution of {column}')\n        plt.xticks(rotation=45)  # Adjust rotation if necessary\n    elif df_cleaned[column].dtype == 'bool' or (df_cleaned[column].dtype == 'int64' and df_cleaned[column].nunique() == 2):\n        # Handle binary data specially\n        df_cleaned[column].astype(int).plot(kind='hist', bins=[-0.5, 0.5, 1.5], title=f'Distribution of {column}', rwidth=0.8)\n        plt.xticks([0, 1])  # Set x-ticks specifically for binary data\n    elif df_cleaned[column].dtype in ['float64', 'int64']:\n        # Handle float and integer data types for non-binary data\n        df_cleaned[column].plot(kind='hist', bins=10, title=f'Distribution of {column}', rwidth=0.8)\n    else:\n        print(f\"Skipping {column} as it is not suitable for histogram plotting.\")\n    \n    plt.show()  # Ensure the plot is shown after each column","metadata":{"execution":{"iopub.status.busy":"2024-06-26T20:38:13.990409Z","iopub.execute_input":"2024-06-26T20:38:13.990852Z","iopub.status.idle":"2024-06-26T20:38:17.816213Z","shell.execute_reply.started":"2024-06-26T20:38:13.990820Z","shell.execute_reply":"2024-06-26T20:38:17.815058Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class_asd_counts = df_cleaned['Class/ASD'].value_counts()\nprint(class_asd_counts)\n\nfor column in df_cleaned.columns:\n    print(f\"{column}: {df_cleaned[column].unique()}\")\n\nprint(df_cleaned.info())\n\ndf_cleaned_nz = df_cleaned","metadata":{"execution":{"iopub.status.busy":"2024-06-26T20:38:17.817934Z","iopub.execute_input":"2024-06-26T20:38:17.818300Z","iopub.status.idle":"2024-06-26T20:38:17.839374Z","shell.execute_reply.started":"2024-06-26T20:38:17.818271Z","shell.execute_reply":"2024-06-26T20:38:17.837977Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Polish Dataset","metadata":{}},{"cell_type":"code","source":"# load polish dataset\ndf, meta = pyreadstat.read_sav('/kaggle/input/qchat-mendeley-polish-toddlers/QCHAT_dataset2 mendeley.sav')\n\n# Check the shape of the DataFrame before dropping duplicates\nprint(\"Shape of DataFrame before dropping duplicates:\", df.shape)\n\n# Drop duplicate rows\ndf.drop_duplicates(inplace=True)\n\n# Check the shape of the DataFrame after dropping duplicates\nprint(\"Shape of DataFrame after dropping duplicates:\", df.shape)\n\nprint(df.head())\nprint(df.describe())\nprint(df.info())\n\ndf = df.rename(columns ={\n    'qchat1recode' : 'A1_Score',\n    'qchat2recode' : 'A2_Score',\n    'qchat5recode' : 'A3_Score',\n    'qchat6recode' : 'A4_Score',\n    'qchat9recode' : 'A5_Score',\n    'qchat10recode' : 'A6_Score',\n    'qchat15recode' : 'A7_Score',\n    'qchat17recode' : 'A8_Score',\n    'qchat19recode' : 'A9_Score',\n    'qchat25recode' : 'A10_Score',\n    'age' : 'age_months',\n    'group' : 'Class/ASD',\n    'sibling_withASD' : 'family_pdd',\n    'Ethnicity' : 'ethnicity',\n    'Sum_QCHAT' : 'result',\n    'sex' : 'gender'\n})\n\nlist(df.columns)","metadata":{"execution":{"iopub.status.busy":"2025-10-06T20:54:31.386021Z","iopub.execute_input":"2025-10-06T20:54:31.386376Z","iopub.status.idle":"2025-10-06T20:54:31.545845Z","shell.execute_reply.started":"2025-10-06T20:54:31.386351Z","shell.execute_reply":"2025-10-06T20:54:31.544548Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# print unique values for each column\nfor column in df.columns:\n    print(f\"{column}: {df[column].unique()}\")","metadata":{"execution":{"iopub.status.busy":"2025-10-06T20:54:37.800088Z","iopub.execute_input":"2025-10-06T20:54:37.800584Z","iopub.status.idle":"2025-10-06T20:54:37.821473Z","shell.execute_reply.started":"2025-10-06T20:54:37.800548Z","shell.execute_reply":"2025-10-06T20:54:37.819762Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# For a single column\nmean_val = df[\"age_months\"].mean()\nstd_val = df[\"age_months\"].std()\nmin_val = df[\"age_months\"].min()\nmax_val = df[\"age_months\"].max()\n\nprint(\"Mean:\", mean_val)\nprint(\"Standard Deviation:\", std_val)\nprint(\"Min:\", min_val)\nprint(\"Max:\", max_val)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-06T20:54:42.902586Z","iopub.execute_input":"2025-10-06T20:54:42.902973Z","iopub.status.idle":"2025-10-06T20:54:42.911967Z","shell.execute_reply.started":"2025-10-06T20:54:42.902942Z","shell.execute_reply":"2025-10-06T20:54:42.910144Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Replace text objects with boolean values\n#for column in ['A1_Score', 'A2_Score', 'A3_Score', 'A4_Score', 'A5_Score', 'A6_Score', 'A7_Score', 'A8_Score', 'A9_Score']:  # Add all your column names here\n#    df[column] = df[column].replace({4: False, 3: False, 2:True, 1: True, 0:True}).infer_objects()\n# Update A10 scoring to reflect the New Zealand dataset\nfor column in ['A1_Score', 'A2_Score', 'A3_Score', 'A4_Score', 'A5_Score', 'A6_Score', 'A7_Score', 'A8_Score', 'A9_Score']:  # Add all your column names here\n    df[column] = df[column].replace({4: True, 3: True, 2:True, 1: False, 0:False}).infer_objects()\ndf['A10_Score'] = df['A10_Score'].replace({4: True, 3: True, 2:True, 1: False, 0:False}).infer_objects()\n\n# for column in ['A1_Score', 'A2_Score', 'A3_Score', 'A4_Score', 'A5_Score', 'A6_Score', 'A7_Score', 'A8_Score', 'A9_Score']:  # Add all your column names here\n#     df[column] = df[column].replace({4: False, 3: False, 2:True, 1: True, 0:True}).infer_objects()\n\nfor column in ['family_pdd']:  # Add all your column names here\n    df[column] = df[column].replace({1: True, 0: False, math.nan:False}).infer_objects()\n\ndf['Class/ASD'] = df['Class/ASD'].replace({1: 1, 7: 0}).infer_objects()\n\n# Male gender represented as 'True' and female represented as 'False'\ndf['gender'] = df['gender'].replace({1: True, 2: False}).infer_objects()\n    \nfor column in df.columns:\n    print(f\"{column}: {df[column].unique()}\")\n\nprint(df.info())","metadata":{"execution":{"iopub.status.busy":"2024-06-26T20:38:18.006448Z","iopub.execute_input":"2024-06-26T20:38:18.007776Z","iopub.status.idle":"2024-06-26T20:38:18.062213Z","shell.execute_reply.started":"2024-06-26T20:38:18.007735Z","shell.execute_reply":"2024-06-26T20:38:18.060520Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Find count of null values\nprint(df.isnull().sum())\n\nsns.heatmap(df.isnull(), cbar=False)","metadata":{"execution":{"iopub.status.busy":"2024-06-26T20:38:18.064249Z","iopub.execute_input":"2024-06-26T20:38:18.064672Z","iopub.status.idle":"2024-06-26T20:38:18.651608Z","shell.execute_reply.started":"2024-06-26T20:38:18.064634Z","shell.execute_reply":"2024-06-26T20:38:18.650283Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# drop irrelevant columns and columns not shared with the other dataset\nprint(\"Current columns in the DataFrame:\", df.columns.tolist())\ndf_cleaned = df.drop(['child_id', 'preterm', 'birthweight', 'result', 'siblings_yesno', 'siblings_number', 'mothers_education', 'qchat13recode', 'qchat21recode', 'qchat23recode', 'qchat3recode', 'qchat7recode', 'qchat11recode', 'qchat4recode', 'qchat8recode', 'qchat12recode', 'qchat14recode', 'qchat18recode', 'qchat16recode', 'qchat20recode', 'qchat22recode', 'qchat24recode'], axis=1)\ndf_cleaned.head()\n\n# Check the result\nprint(df_cleaned.shape)\nprint(\"Current columns in the DataFrame:\", df_cleaned.columns.tolist())","metadata":{"execution":{"iopub.status.busy":"2024-06-26T20:38:18.653344Z","iopub.execute_input":"2024-06-26T20:38:18.654707Z","iopub.status.idle":"2024-06-26T20:38:18.666814Z","shell.execute_reply.started":"2024-06-26T20:38:18.654650Z","shell.execute_reply":"2024-06-26T20:38:18.665324Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Iterate over each column in the DataFrame\nfor column in df_cleaned.columns:\n    # Check data type of the column\n    if df_cleaned[column].dtype == 'object':  # Categorical data\n        # Generate a bar plot for categorical data\n        df_cleaned[column].value_counts().plot(kind='bar', title=f'Distribution of {column}')\n        plt.xticks(rotation=45)  # Adjust rotation if necessary\n    elif df_cleaned[column].dtype == 'bool' or (df_cleaned[column].dtype == 'int64' and df_cleaned[column].nunique() == 2):\n        # Handle binary data specially\n        df_cleaned[column].astype(int).plot(kind='hist', bins=[-0.5, 0.5, 1.5], title=f'Distribution of {column}', rwidth=0.8)\n        plt.xticks([0, 1])  # Set x-ticks specifically for binary data\n    elif df_cleaned[column].dtype in ['float64', 'int64']:\n        # Handle float and integer data types for non-binary data\n        df_cleaned[column].plot(kind='hist', bins=10, title=f'Distribution of {column}', rwidth=0.8)\n    else:\n        print(f\"Skipping {column} as it is not suitable for histogram plotting.\")\n    \n    plt.show()  # Ensure the plot is shown after each column","metadata":{"execution":{"iopub.status.busy":"2024-06-26T20:38:18.668934Z","iopub.execute_input":"2024-06-26T20:38:18.669290Z","iopub.status.idle":"2024-06-26T20:38:22.211452Z","shell.execute_reply.started":"2024-06-26T20:38:18.669262Z","shell.execute_reply":"2024-06-26T20:38:22.209910Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# drop irrelevant columns and columns not shared with the other dataset\nprint(\"Current columns in the DataFrame:\", df.columns.tolist())\ndf_cleaned = df.drop(['child_id', 'preterm', 'birthweight', 'result', 'siblings_yesno', 'siblings_number', 'mothers_education', 'qchat13recode', 'qchat21recode', 'qchat23recode', 'qchat3recode', 'qchat7recode', 'qchat11recode', 'qchat4recode', 'qchat8recode', 'qchat12recode', 'qchat14recode', 'qchat18recode', 'qchat16recode', 'qchat20recode', 'qchat22recode', 'qchat24recode'], axis=1)\ndf_cleaned.head()\n\n# Check the result\nprint(df_cleaned.shape)\nprint(\"Current columns in the DataFrame:\", df_cleaned.columns.tolist())","metadata":{"execution":{"iopub.status.busy":"2024-06-26T20:38:22.213438Z","iopub.execute_input":"2024-06-26T20:38:22.213837Z","iopub.status.idle":"2024-06-26T20:38:22.224921Z","shell.execute_reply.started":"2024-06-26T20:38:22.213807Z","shell.execute_reply":"2024-06-26T20:38:22.223680Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class_asd_counts = df_cleaned['Class/ASD'].value_counts()\nprint(class_asd_counts)\n\nfor column in df_cleaned.columns:\n    print(f\"{column}: {df_cleaned[column].unique()}\")\n\nprint(df_cleaned.info())\n\ndf_cleaned_polish = df_cleaned","metadata":{"execution":{"iopub.status.busy":"2024-06-26T20:38:22.227326Z","iopub.execute_input":"2024-06-26T20:38:22.227920Z","iopub.status.idle":"2024-06-26T20:38:22.258315Z","shell.execute_reply.started":"2024-06-26T20:38:22.227876Z","shell.execute_reply":"2024-06-26T20:38:22.256918Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Saudi Dataset","metadata":{}},{"cell_type":"code","source":"# Load file\npath = '/kaggle/input/asd-screening-data-for-toddlers-in-saudi-arabia/Autism Spectrum Disorder Screening Data for Toddlers in Saudi Arabia Data Set.csv'\ndata = pd.read_csv(path)\n# data, meta = arff.loadarff(path)\n\n# Convert the data to a Pandas DataFrame\ndf = pd.DataFrame(data)\n\n# If the data contains byte strings, convert them to regular strings\ndf = df.map(lambda x: x.decode('utf-8') if isinstance(x, bytes) else x)\n\n# Check the shape of the DataFrame before dropping duplicates\nprint(\"Shape of DataFrame before dropping duplicates:\", df.shape)\n\n# Drop duplicate rows\ndf.drop_duplicates(inplace=True)\n\n# Check the shape of the DataFrame after dropping duplicates\nprint(\"Shape of DataFrame after dropping duplicates:\", df.shape)\n\nprint(df.head())\nprint(df.describe())\nprint(df.info())\n\n# Rename misspelled / unclear columns\n# family_pdd = direct family member with pervasive developmental disorder\n# Five disorders are identified under the category of pervasive developmental disorders: (1) autistic disorder, (2) Rett's disorder, (3) childhood disintegrative disorder, (4) Asperger's syndrome, and (5) pervasive developmental disorder-not otherwise specified, or PDD-NOS (DSM-IV-TR, 2000).\n\ndf = df.rename(columns ={\n    'A1' : 'A1_Score',\n    'A2' : 'A2_Score',\n    'A3' : 'A3_Score',\n    'A4' : 'A4_Score',\n    'A5' : 'A5_Score',\n    'A6' : 'A6_Score',\n    'A7' : 'A7_Score',\n    'A8' : 'A8_Score',\n    'A9' : 'A9_Score',\n    'A10' : 'A10_Score',\n    'Age' : 'age_months',\n    'Class' : 'Class/ASD',\n    'Family member with ASD history' : 'family_pdd',\n    'Jaundice' : 'jaundice',\n    'Ethnicity' : 'ethnicity',\n    'Screening Score' : 'result',\n    'Gender' : 'gender',\n    'Who is completing the test' : 'relation'\n})\n\nlist(df.columns)","metadata":{"execution":{"iopub.status.busy":"2025-10-06T20:31:09.107430Z","iopub.execute_input":"2025-10-06T20:31:09.108082Z","iopub.status.idle":"2025-10-06T20:31:09.202866Z","shell.execute_reply.started":"2025-10-06T20:31:09.108037Z","shell.execute_reply":"2025-10-06T20:31:09.201689Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# print unique values for each column\nfor column in df.columns:\n    print(f\"{column}: {df[column].unique()}\")","metadata":{"execution":{"iopub.status.busy":"2025-10-06T20:31:14.859221Z","iopub.execute_input":"2025-10-06T20:31:14.860564Z","iopub.status.idle":"2025-10-06T20:31:14.874100Z","shell.execute_reply.started":"2025-10-06T20:31:14.860504Z","shell.execute_reply":"2025-10-06T20:31:14.872289Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# For a single column\nmean_val = df[\"age_months\"].mean()\nstd_val = df[\"age_months\"].std()\nmin_val = df[\"age_months\"].min()\nmax_val = df[\"age_months\"].max()\n\nprint(\"Mean:\", mean_val)\nprint(\"Standard Deviation:\", std_val)\nprint(\"Min:\", min_val)\nprint(\"Max:\", max_val)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-06T20:31:18.581863Z","iopub.execute_input":"2025-10-06T20:31:18.583029Z","iopub.status.idle":"2025-10-06T20:31:18.591856Z","shell.execute_reply.started":"2025-10-06T20:31:18.582981Z","shell.execute_reply":"2025-10-06T20:31:18.590391Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\nfrom scipy import stats\n\n# Example dataframe\n# df = pd.DataFrame({\n#     \"age\": [...],\n#     \"result\": [...]\n# })\n\n# Split into groups\ngroup0 = df.loc[df[\"result\"] == 0, \"age_months\"]\ngroup1 = df.loc[df[\"result\"] == 1, \"age_months\"]\n\n# Independent samples t-test\nt_stat, p_val_ttest = stats.ttest_ind(group0, group1, equal_var=False)  # Welch’s t-test\nprint(\"T-test results:\")\nprint(\"t-statistic =\", t_stat, \"p-value =\", p_val_ttest)\n\n# Mann–Whitney U test (non-parametric)\nu_stat, p_val_mwu = stats.mannwhitneyu(group0, group1, alternative=\"two-sided\")\nprint(\"\\nMann-Whitney U test results:\")\nprint(\"U-statistic =\", u_stat, \"p-value =\", p_val_mwu)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-06T20:35:46.665081Z","iopub.execute_input":"2025-10-06T20:35:46.667186Z","iopub.status.idle":"2025-10-06T20:35:46.685016Z","shell.execute_reply.started":"2025-10-06T20:35:46.667107Z","shell.execute_reply":"2025-10-06T20:35:46.683681Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Replace text objects with boolean values\nfor column in ['A1_Score', 'A2_Score', 'A3_Score', 'A4_Score', 'A5_Score', 'A6_Score', 'A7_Score', 'A8_Score', 'A9_Score', 'A10_Score']:  # Add all your column names here\n    df[column] = df[column].replace({1: True, 0: False}).infer_objects()\n\nfor column in ['family_pdd']:  # Add all your column names here\n    df[column] = df[column].replace({'Yes': True, 'No': False}).infer_objects()\n\ndf['Class/ASD'] = df['Class/ASD'].replace({1: 1, 0: 0}).infer_objects()\n\n# Male gender represented as 'True' and female represented as 'False'\ndf['gender'] = df['gender'].replace({'Male': True, 'Female': False}).infer_objects()\n    \nfor column in df.columns:\n    print(f\"{column}: {df[column].unique()}\")\n\nprint(df.info())","metadata":{"execution":{"iopub.status.busy":"2024-06-26T20:38:22.363033Z","iopub.execute_input":"2024-06-26T20:38:22.363472Z","iopub.status.idle":"2024-06-26T20:38:22.404293Z","shell.execute_reply.started":"2024-06-26T20:38:22.363442Z","shell.execute_reply":"2024-06-26T20:38:22.402906Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Find count of null values\nprint(df.isnull().sum())\n\nsns.heatmap(df.isnull(), cbar=False)","metadata":{"execution":{"iopub.status.busy":"2024-06-26T20:38:22.406006Z","iopub.execute_input":"2024-06-26T20:38:22.406460Z","iopub.status.idle":"2024-06-26T20:38:22.917547Z","shell.execute_reply.started":"2024-06-26T20:38:22.406422Z","shell.execute_reply":"2024-06-26T20:38:22.916354Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# drop irrelevant columns and columns not shared with the other dataset\nprint(\"Current columns in the DataFrame:\", df.columns.tolist())\ndf_cleaned = df.drop(['result', 'Region', 'relation'], axis=1)\ndf_cleaned.head()\n\n# Check the result\nprint(df_cleaned.shape)\nprint(\"Current columns in the DataFrame:\", df_cleaned.columns.tolist())","metadata":{"execution":{"iopub.status.busy":"2024-06-26T20:38:22.919058Z","iopub.execute_input":"2024-06-26T20:38:22.919454Z","iopub.status.idle":"2024-06-26T20:38:22.929602Z","shell.execute_reply.started":"2024-06-26T20:38:22.919424Z","shell.execute_reply":"2024-06-26T20:38:22.928102Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Iterate over each column in the DataFrame\nfor column in df_cleaned.columns:\n    # Check data type of the column\n    if df_cleaned[column].dtype == 'object':  # Categorical data\n        # Generate a bar plot for categorical data\n        df_cleaned[column].value_counts().plot(kind='bar', title=f'Distribution of {column}')\n        plt.xticks(rotation=45)  # Adjust rotation if necessary\n    elif df_cleaned[column].dtype == 'bool' or (df_cleaned[column].dtype == 'int64' and df_cleaned[column].nunique() == 2):\n        # Handle binary data specially\n        df_cleaned[column].astype(int).plot(kind='hist', bins=[-0.5, 0.5, 1.5], title=f'Distribution of {column}', rwidth=0.8)\n        plt.xticks([0, 1])  # Set x-ticks specifically for binary data\n    elif df_cleaned[column].dtype in ['float64', 'int64']:\n        # Handle float and integer data types for non-binary data\n        df_cleaned[column].plot(kind='hist', bins=10, title=f'Distribution of {column}', rwidth=0.8)\n    else:\n        print(f\"Skipping {column} as it is not suitable for histogram plotting.\")\n    \n    plt.show()  # Ensure the plot is shown after each column","metadata":{"execution":{"iopub.status.busy":"2024-06-26T20:38:22.931494Z","iopub.execute_input":"2024-06-26T20:38:22.931950Z","iopub.status.idle":"2024-06-26T20:38:26.466129Z","shell.execute_reply.started":"2024-06-26T20:38:22.931911Z","shell.execute_reply":"2024-06-26T20:38:26.464869Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class_asd_counts = df_cleaned['Class/ASD'].value_counts()\nprint(class_asd_counts)\n\nfor column in df_cleaned.columns:\n    print(f\"{column}: {df_cleaned[column].unique()}\")\n\nprint(df_cleaned.info())\n\ndf_cleaned_saudi = df_cleaned","metadata":{"execution":{"iopub.status.busy":"2024-06-26T20:38:26.467798Z","iopub.execute_input":"2024-06-26T20:38:26.468245Z","iopub.status.idle":"2024-06-26T20:38:26.487595Z","shell.execute_reply.started":"2024-06-26T20:38:26.468214Z","shell.execute_reply":"2024-06-26T20:38:26.486324Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Preprocessing","metadata":{}},{"cell_type":"code","source":"# Separating features and labels\n# nz dataset\nX_nz = df_cleaned_nz.drop('Class/ASD', axis=1)  # Features\ny_nz = df_cleaned_nz['Class/ASD']  # Labels\n\n# Polish dataset\nX_polish = df_cleaned_polish.drop('Class/ASD', axis=1)  # Features\ny_polish = df_cleaned_polish['Class/ASD']  # Labels\n\n# Saudi dataset\nX_saudi = df_cleaned_saudi.drop('Class/ASD', axis=1)  # Features\ny_saudi = df_cleaned_saudi['Class/ASD']  # Labels\n\n# Using only decision tree-based models, so scaling is unnecessary","metadata":{"execution":{"iopub.status.busy":"2024-06-26T20:38:26.489332Z","iopub.execute_input":"2024-06-26T20:38:26.489691Z","iopub.status.idle":"2024-06-26T20:38:26.516564Z","shell.execute_reply.started":"2024-06-26T20:38:26.489660Z","shell.execute_reply":"2024-06-26T20:38:26.515027Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Baseline Model Testing / Feature Importance Exploration","metadata":{}},{"cell_type":"markdown","source":"## Polish Dataset","metadata":{}},{"cell_type":"markdown","source":"### XGBoost","metadata":{}},{"cell_type":"code","source":"# Initialize the XGBoost model\nxgb_model_polish = XGBClassifier(use_label_encoder=False, eval_metric='logloss')\n\n# Define the number of folds for cross-validation\nk = 5  # Number of folds. k=5 or k=10 is often recommended\ncv = StratifiedKFold(n_splits=k, shuffle=True, random_state=42)\n\n# Specify the parameter grid to search\nparam_dist = {\n    'n_estimators': [100, 200, 300, 400],\n    'max_depth': [1, 3, 5, 7, 9, 10],  # Typical values for depth in XGBoost\n    'learning_rate': [0.01, 0.1, 0.2, 0.3],  # Learning rate or eta\n    'subsample': [0.5, 0.75, 1],  # Subsample ratio of the training instances\n    'colsample_bytree': [0.5, 0.7, 1],  # Subsample ratio of columns when constructing each tree\n    'gamma': [0, 0.1, 0.2, 0.3, 0.4, 0.5],  # Minimum loss reduction required to make a further partition\n    'reg_lambda': [1, 2, 3, 4, 5],  # L2 regularization term on weights\n    'reg_alpha': [0, 0.1, 0.2]  # L1 regularization term on weights\n}\n\n# Define different scoring metrics\nscoring = {\n    'accuracy': 'accuracy',\n    'precision': make_scorer(precision_score),\n    'recall': make_scorer(recall_score),\n    'specificity': make_scorer(specificity_score),\n    'roc_auc': 'roc_auc'\n}\n\n# Set up the randomized search with cross-validation\nrandom_search = RandomizedSearchCV(\n    estimator=xgb_model_polish,\n    param_distributions=param_dist,\n    n_iter=100,  # Number of parameter settings sampled\n    scoring='accuracy',  # Can be changed according to what metric you care about\n    cv=cv,\n    verbose=1,\n    random_state=42,\n    n_jobs=-1  # Use all available cores\n)\n\n# Fit RandomizedSearchCV to the data\nrandom_search.fit(X_polish, y_polish)\n\n# Print the best parameters and the corresponding score\nprint(\"Best parameters found: \", random_search.best_params_)\nprint(\"Best accuracy found: \", random_search.best_score_)","metadata":{"execution":{"iopub.status.busy":"2024-06-26T20:38:26.518701Z","iopub.execute_input":"2024-06-26T20:38:26.519179Z","iopub.status.idle":"2024-06-26T20:38:45.635381Z","shell.execute_reply.started":"2024-06-26T20:38:26.519148Z","shell.execute_reply":"2024-06-26T20:38:45.634287Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Initialize the XGBoost model with relevant hyperparameters\nxgb_model_polish = XGBClassifier(\n    n_estimators=400,\n    max_depth=1,\n    learning_rate=0.3,\n    subsample=1,\n    colsample_bytree=1,\n    gamma=0.5,\n    reg_lambda=2,\n    reg_alpha=0,\n    use_label_encoder=False,\n    eval_metric='logloss'\n)\n\n# Define the number of folds for cross-validation\nk = 5  # Number of folds\ncv = StratifiedKFold(n_splits=k, shuffle=True, random_state=42)\n\n# Define scoring metrics\nscoring = {\n    'balanced_accuracy': make_scorer(balanced_accuracy_score),\n    'sensitivity': make_scorer(recall_score),\n    'specificity': make_scorer(specificity_score),\n    'roc_auc': 'roc_auc'\n}\n\n# Compute the correlation matrix\ncorrelation_matrix = X_polish.corr()\n\n# Plot the correlation matrix heatmap\nplt.figure(figsize=(12, 10))\nsns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', vmin=-1, vmax=1)\nplt.title('Correlation Matrix Heatmap Polish')\nplt.show()\n\n# Perform cross-validation and return estimators\ncv_results = cross_validate(xgb_model_polish, X_polish, y_polish, cv=cv, scoring=scoring, return_estimator=True)\n\n# Collect predictions for the confusion matrix\ny_pred = cross_val_predict(xgb_model_polish, X_polish, y_polish, cv=cv)\n\n# Compute the confusion matrix\ncm = confusion_matrix(y_polish, y_pred)\ncm_display = ConfusionMatrixDisplay(confusion_matrix=cm)\n\n# Print metrics\nprint(f\"ROC-AUC across {k} folds: {np.mean(cv_results['test_roc_auc']):.2f} ± {np.std(cv_results['test_roc_auc']):.2f}\")\nfor metric in ['test_balanced_accuracy', 'test_sensitivity', 'test_specificity', 'test_roc_auc']:\n    print(f\"{metric.replace('test_', '').replace('_', ' ').capitalize()} across {k} folds: {np.mean(cv_results[metric]):.2f} ± {np.std(cv_results[metric]):.2f}\")\n\n# Collect all feature importances\nfeature_importances = np.zeros(X_polish.shape[1])\nfor estimator in cv_results['estimator']:\n    feature_importances += estimator.feature_importances_\n\n# Average feature importances\nfeature_importances /= k\n\nfeatures = X_polish.columns\n\n# Print feature importances in order\nprint(\"Feature Importances:\")\nsorted_indices = np.argsort(feature_importances)[::-1]  # Sort indices in descending order of importance\nfor i in sorted_indices:\n    print(f\"{features[i]}: {feature_importances[i]}\")\n\n# Plot feature importances\nindices = np.argsort(feature_importances)\nplt.figure(figsize=(10, 8))\nplt.title('Feature Importances')\nplt.barh(range(len(indices)), feature_importances[indices], color='b', align='center')\nplt.yticks(range(len(indices)), [features[i] for i in indices])\nplt.xlabel('Relative Importance')\nplt.show()\n\n# Plot the confusion matrix\nplt.figure()\ncm_display.plot(cmap=plt.cm.Blues)\nplt.title('Confusion Matrix')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-06-26T20:38:45.640363Z","iopub.execute_input":"2024-06-26T20:38:45.642805Z","iopub.status.idle":"2024-06-26T20:38:48.456191Z","shell.execute_reply.started":"2024-06-26T20:38:45.642759Z","shell.execute_reply":"2024-06-26T20:38:48.454819Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### 0.3 Cutoff for positive prediction","metadata":{}},{"cell_type":"code","source":"# Custom scorer for specificity\ndef specificity_score(y_true, y_pred):\n    cm = confusion_matrix(y_true, y_pred)\n    tn, fp, fn, tp = cm.ravel()\n    return tn / (tn + fp)\n\n# Assuming X_polish and y_polish are your feature matrix and target vector\n\n# Initialize the XGBoost model with relevant hyperparameters\nxgb_model_polish = XGBClassifier(\n    n_estimators=400,\n    max_depth=1,\n    learning_rate=0.3,\n    subsample=1,\n    colsample_bytree=1,\n    gamma=0.5,\n    reg_lambda=2,\n    reg_alpha=0,\n    use_label_encoder=False,\n    eval_metric='logloss'\n)\n\n# Define the number of folds for cross-validation\nk = 5  # Number of folds\ncv = StratifiedKFold(n_splits=k, shuffle=True, random_state=42)\n\n# Define scoring metrics\nscoring = {\n    'balanced_accuracy': make_scorer(balanced_accuracy_score),\n    'sensitivity': make_scorer(recall_score),\n    'specificity': make_scorer(specificity_score),\n    'roc_auc': 'roc_auc'\n}\n\n# Perform cross-validation and return estimators\ncv_results = cross_validate(xgb_model_polish, X_polish, y_polish, cv=cv, scoring=scoring, return_estimator=True)\n\n# Collect predictions for the confusion matrix with custom threshold\ny_pred_proba = cross_val_predict(xgb_model_polish, X_polish, y_polish, cv=cv, method='predict_proba')[:, 1]\ny_pred = (y_pred_proba >= 0.3).astype(int)\n\n# Compute the confusion matrix\ncm = confusion_matrix(y_polish, y_pred)\ncm_display = ConfusionMatrixDisplay(confusion_matrix=cm)\n\n# Print metrics\nprint(f\"ROC-AUC across {k} folds: {np.mean(cv_results['test_roc_auc']):.2f} ± {np.std(cv_results['test_roc_auc']):.2f}\")\nfor metric in ['test_balanced_accuracy', 'test_sensitivity', 'test_specificity', 'test_roc_auc']:\n    print(f\"{metric.replace('test_', '').replace('_', ' ').capitalize()} across {k} folds: {np.mean(cv_results[metric]):.2f} ± {np.std(cv_results[metric]):.2f}\")\n\n# Plot the confusion matrix\nplt.figure()\ncm_display.plot(cmap=plt.cm.Blues)\nplt.title('Confusion Matrix')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-06-26T20:38:48.465180Z","iopub.execute_input":"2024-06-26T20:38:48.465898Z","iopub.status.idle":"2024-06-26T20:38:50.218046Z","shell.execute_reply.started":"2024-06-26T20:38:48.465865Z","shell.execute_reply":"2024-06-26T20:38:50.216703Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### Recursive Feature Elimination","metadata":{}},{"cell_type":"code","source":"# Initialize the XGBoost model with relevant hyperparameters\nxgb_model_polish = XGBClassifier(\n    n_estimators=400,\n    max_depth=1,\n    learning_rate=0.3,\n    subsample=1,\n    colsample_bytree=1,\n    gamma=0.5,\n    reg_lambda=2,\n    reg_alpha=0,\n    use_label_encoder=False,\n    eval_metric='logloss'\n)\n\n# Define the number of folds for cross-validation\nk = 5  # Number of folds\ncv = StratifiedKFold(n_splits=k, shuffle=True, random_state=42)\n\n# Define different scoring metrics\nscoring = {\n    'sensitivity': 'recall',\n    'specificity': make_scorer(specificity_score),\n    'balanced_accuracy': make_scorer(balanced_accuracy_score)\n}\n\n# Initialize lists to store metrics for each number of features\nmetrics_history = {\n    'sensitivity': [],\n    'specificity': [],\n    'balanced_accuracy': []\n}\n\nnum_features = X_polish.shape[1]\nfeatures_list = X_polish.columns.tolist()  # Store initial full feature list\n\n# Perform RFE with cross-validation and track metrics\nfor i in range(num_features, 0, -1):\n    rfe = RFE(estimator=xgb_model_polish, n_features_to_select=i, step=1)\n    rfe.fit(X_polish, y_polish)\n    \n    # Current set of selected features\n    current_features = list(X_polish.columns[rfe.support_])\n    print(f\"Features retained ({i}): {current_features}\")\n    \n    # Evaluate metrics for the selected features\n    cv_results = cross_validate(rfe.estimator_, rfe.transform(X_polish), y_polish, cv=cv, scoring=scoring)\n    \n    # Store results for plotting\n    for metric in scoring:\n        mean_score = cv_results[f'test_{metric}'].mean()\n        std_score = cv_results[f'test_{metric}'].std()\n        metrics_history[metric].append(mean_score)\n        print(f\"{metric.capitalize()} with {i} features: {mean_score:.2f} ± {std_score:.2f}\")\n\n# Plotting the metrics over the number of features\nplt.figure(figsize=(12, 8))\nfeature_counts = list(range(num_features, 0, -1))\nfor metric, values in metrics_history.items():\n    plt.plot(feature_counts, values, marker='o', linestyle='-', label=metric.capitalize())\n\nplt.title('Polish-Trained Model Performance Across Feature Counts')\nplt.xlabel('Number of Features')\nplt.ylabel('Model Performance')\nplt.legend()\n# plt.gca().invert_xaxis()  # Optional: Invert x-axis to show decreasing number of features\nplt.grid(True)\n# Save the plot to /kaggle/working directory\nplt.savefig('/kaggle/working/model_performance_across_feature_counts_polish.png')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-06-26T20:38:50.219668Z","iopub.execute_input":"2024-06-26T20:38:50.220016Z","iopub.status.idle":"2024-06-26T20:39:05.115929Z","shell.execute_reply.started":"2024-06-26T20:38:50.219989Z","shell.execute_reply":"2024-06-26T20:39:05.114669Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### 4 Features Only","metadata":{}},{"cell_type":"code","source":"# Select only the 4 retained features\nretained_features = ['A2_Score', 'A3_Score', 'A4_Score', 'A5_Score']\nX_polish_reduced = X_polish[retained_features]\n\n# Initialize the XGBoost model with relevant hyperparameters\nxgb_model_polish = XGBClassifier(\n    n_estimators=400,\n    max_depth=1,\n    learning_rate=0.3,\n    subsample=1,\n    colsample_bytree=1,\n    gamma=0.5,\n    reg_lambda=2,\n    reg_alpha=0,\n    use_label_encoder=False,\n    eval_metric='logloss'\n)\n\n# Define the number of folds for cross-validation\nk = 5  # Number of folds\ncv = StratifiedKFold(n_splits=k, shuffle=True, random_state=42)\n\n# Define scoring metrics\nscoring = {\n    'balanced_accuracy': make_scorer(balanced_accuracy_score),\n    'sensitivity': make_scorer(recall_score),\n    'specificity': make_scorer(specificity_score),\n    'roc_auc': 'roc_auc'\n}\n\n# Perform cross-validation and return estimators\ncv_results = cross_validate(xgb_model_polish, X_polish_reduced, y_polish, cv=cv, scoring=scoring, return_estimator=True)\n\n# Collect predictions for the confusion matrix\ny_pred = cross_val_predict(xgb_model_polish, X_polish_reduced, y_polish, cv=cv)\n\n# Compute the confusion matrix\ncm = confusion_matrix(y_polish, y_pred)\ncm_display = ConfusionMatrixDisplay(confusion_matrix=cm)\n\n# Print metrics\nprint(f\"ROC-AUC across {k} folds: {np.mean(cv_results['test_roc_auc']):.2f} ± {np.std(cv_results['test_roc_auc']):.2f}\")\nfor metric in ['test_balanced_accuracy', 'test_sensitivity', 'test_specificity', 'test_roc_auc']:\n    print(f\"{metric.replace('test_', '').replace('_', ' ').capitalize()} across {k} folds: {np.mean(cv_results[metric]):.2f} ± {np.std(cv_results[metric]):.2f}\")\n\n# Plot the confusion matrix\nplt.figure()\ncm_display.plot(cmap=plt.cm.Blues)\nplt.title('Confusion Matrix')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-06-26T20:39:05.117385Z","iopub.execute_input":"2024-06-26T20:39:05.117753Z","iopub.status.idle":"2024-06-26T20:39:06.423968Z","shell.execute_reply.started":"2024-06-26T20:39:05.117722Z","shell.execute_reply":"2024-06-26T20:39:06.422734Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Select only the 4 retained features\nretained_features = ['A2_Score', 'A3_Score', 'A4_Score', 'A5_Score']\nX_polish_reduced = X_polish[retained_features]\n\n# Initialize the XGBoost model with relevant hyperparameters\nxgb_model_polish = XGBClassifier(\n    n_estimators=400,\n    max_depth=1,\n    learning_rate=0.3,\n    subsample=1,\n    colsample_bytree=1,\n    gamma=0.5,\n    reg_lambda=2,\n    reg_alpha=0,\n    use_label_encoder=False,\n    eval_metric='logloss'\n)\n\n# Define the number of folds for cross-validation\nk = 5  # Number of folds\ncv = StratifiedKFold(n_splits=k, shuffle=True, random_state=42)\n\n# Define scoring metrics\nscoring = {\n    'balanced_accuracy': make_scorer(balanced_accuracy_score),\n    'sensitivity': make_scorer(recall_score),\n    'specificity': make_scorer(specificity_score),\n    'roc_auc': 'roc_auc'\n}\n\n# Perform cross-validation and return estimators\ncv_results = cross_validate(xgb_model_polish, X_polish_reduced, y_polish, cv=cv, scoring=scoring, return_estimator=True)\n\n# Collect predictions for the confusion matrix with custom threshold\ny_pred_proba = cross_val_predict(xgb_model_polish, X_polish_reduced, y_polish, cv=cv, method='predict_proba')[:, 1]\ny_pred = (y_pred_proba >= 0.3).astype(int)\n\n# Compute the confusion matrix\ncm = confusion_matrix(y_polish, y_pred)\ncm_display = ConfusionMatrixDisplay(confusion_matrix=cm)\n\n# Print metrics\nprint(f\"ROC-AUC across {k} folds: {np.mean(cv_results['test_roc_auc']):.2f} ± {np.std(cv_results['test_roc_auc']):.2f}\")\nfor metric in ['test_balanced_accuracy', 'test_sensitivity', 'test_specificity', 'test_roc_auc']:\n    print(f\"{metric.replace('test_', '').replace('_', ' ').capitalize()} across {k} folds: {np.mean(cv_results[metric]):.2f} ± {np.std(cv_results[metric]):.2f}\")\n\n# Plot the confusion matrix\nplt.figure()\ncm_display.plot(cmap=plt.cm.Blues)\nplt.title('Confusion Matrix')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-06-26T20:39:06.425524Z","iopub.execute_input":"2024-06-26T20:39:06.425874Z","iopub.status.idle":"2024-06-26T20:39:07.689581Z","shell.execute_reply.started":"2024-06-26T20:39:06.425845Z","shell.execute_reply":"2024-06-26T20:39:07.688173Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## New Zealand Dataset","metadata":{}},{"cell_type":"markdown","source":"### Decision Tree","metadata":{}},{"cell_type":"code","source":"# Define the Decision Tree model\ntree_model_nz_paramSearch = DecisionTreeClassifier()\n\n# Specify the parameter grid to search\nparam_dist = {\n    'criterion': ['gini', 'entropy'],\n    'max_depth': [15, 20, 25], # explored range 10 to 50\n    'min_samples_split': [2, 5, 10],\n    'min_samples_leaf': [1, 2, 4],\n    'max_features': [None, 'sqrt', 'log2']\n}\n\n# Define the number of folds for cross-validation\ncv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n\n# Set up the randomized search with cross-validation\nrandom_search = RandomizedSearchCV(\n    estimator=tree_model_nz_paramSearch,\n    param_distributions=param_dist,\n    n_iter=100,  # Number of parameter settings sampled\n    scoring='accuracy',  # Can be changed according to what metric you care about\n    cv=cv,\n    verbose=1,\n    random_state=42,\n    n_jobs=-1  # Use all available cores\n)\n\n# Fit RandomizedSearchCV to the data\nrandom_search.fit(X_nz, y_nz)\n\n# Print the best parameters and the corresponding score\nprint(\"Best parameters found: \", random_search.best_params_)\nprint(\"Best accuracy found: \", random_search.best_score_)\n\n# Optional: Extract the best model and use it for further analysis or validation\nbest_tree_model = random_search.best_estimator_","metadata":{"execution":{"iopub.status.busy":"2024-06-26T20:39:07.691555Z","iopub.execute_input":"2024-06-26T20:39:07.692044Z","iopub.status.idle":"2024-06-26T20:39:09.488035Z","shell.execute_reply.started":"2024-06-26T20:39:07.692010Z","shell.execute_reply":"2024-06-26T20:39:09.486476Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Initialize the Decision Tree model\ntree_model_nz = DecisionTreeClassifier(min_samples_split=2, min_samples_leaf=1, max_features='sqrt', max_depth=25, criterion='entropy')\n\n# Define the number of folds for cross-validation\nk = 5  # Number of folds\ncv = StratifiedKFold(n_splits=k, shuffle=True, random_state=42)\n\n# Define different scoring metrics\nscoring = {\n    'accuracy': make_scorer(accuracy_score),\n    'precision': make_scorer(precision_score, zero_division=0),\n    'recall': make_scorer(recall_score, zero_division=0),\n    'specificity': make_scorer(specificity_score),\n    'roc_auc': 'roc_auc'\n}\n\n# Perform cross-validation\ncv_results = cross_validate(tree_model_nz, X_nz, y_nz, cv=cv, scoring=scoring, return_estimator=True)\n\n# Collect predictions for confusion matrix\ny_pred = cross_val_predict(tree_model_nz, X_nz, y_nz, cv=cv)\n\n# Compute the confusion matrix\ncm = confusion_matrix(y_nz, y_pred)\ncm_display = ConfusionMatrixDisplay(cm)\n\n# Printing metrics\nprint(f\"ROC-AUC across {k} folds: {np.mean(cv_results['test_roc_auc']):.2f} ± {np.std(cv_results['test_roc_auc']):.2f}\")\nfor metric in ['test_accuracy', 'test_precision', 'test_recall', 'test_roc_auc', 'test_specificity']:\n    print(f\"{metric.capitalize()} across {k} folds: {np.mean(cv_results[metric]):.2f} ± {np.std(cv_results[metric]):.2f}\")","metadata":{"execution":{"iopub.status.busy":"2024-06-26T20:39:09.490094Z","iopub.execute_input":"2024-06-26T20:39:09.491220Z","iopub.status.idle":"2024-06-26T20:39:09.653908Z","shell.execute_reply.started":"2024-06-26T20:39:09.491170Z","shell.execute_reply":"2024-06-26T20:39:09.652803Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Random Forest","metadata":{}},{"cell_type":"code","source":"# Initialize the Random Forest model\nforest_model_nz = RandomForestClassifier()\n\n# Define the number of folds for cross-validation\nk = 5  # Number of folds. k=5 or k=10 is often recommended\ncv = StratifiedKFold(n_splits=k, shuffle=True, random_state=42)\n\n# Specify the parameter grid to search\nparam_dist = {\n    'n_estimators': [100, 200, 300, 400],  # Number of trees in the forest\n    'criterion': ['gini', 'entropy'],\n    'max_depth': [40, 50, 60, 70], # explored none to 10 to ??\n    'min_samples_split': [2, 3, 4], # explored 2 to 10\n    'min_samples_leaf': [1, 2, 4],\n    'max_features': ['sqrt', 'log2'],  # Options for the number of features to consider when looking for the best split\n    'bootstrap': [True, False]  # Method for sampling data points (with or without replacement)\n}\n\n# Define different scoring metrics\nscoring = {\n    'accuracy': make_scorer(accuracy_score),\n    'precision': make_scorer(precision_score),\n    'recall': make_scorer(recall_score),\n    'specificity': make_scorer(specificity_score),\n    'roc_auc': 'roc_auc'\n}\n\n# Set up the randomized search with cross-validation\nrandom_search = RandomizedSearchCV(\n    estimator=forest_model_nz,\n    param_distributions=param_dist,\n    n_iter=100,  # Number of parameter settings sampled\n    scoring='accuracy',  # Can be changed according to what metric you care about\n    cv=cv,\n    verbose=1,\n    random_state=42,\n    n_jobs=-1  # Use all available cores\n)\n\n# Fit RandomizedSearchCV to the data\nrandom_search.fit(X_nz, y_nz)\n\n# Print the best parameters and the corresponding score\nprint(\"Best parameters found: \", random_search.best_params_)\nprint(\"Best accuracy found: \", random_search.best_score_)","metadata":{"execution":{"iopub.status.busy":"2024-06-26T20:39:09.655415Z","iopub.execute_input":"2024-06-26T20:39:09.655740Z","iopub.status.idle":"2024-06-26T20:41:00.045551Z","shell.execute_reply.started":"2024-06-26T20:39:09.655712Z","shell.execute_reply":"2024-06-26T20:41:00.044278Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Initialize the Random Forest model with specified hyperparameters\nforest_model_nz = RandomForestClassifier(\n    n_estimators=200,\n    min_samples_split=2,\n    min_samples_leaf=1,\n    max_features='log2',\n    max_depth=50,\n    criterion='gini',\n    random_state=42,\n    bootstrap=False\n)\n\n# Define the number of folds for cross-validation\nk = 5  # Number of folds\ncv = StratifiedKFold(n_splits=k, shuffle=True, random_state=42)\n\n# Define scoring metrics\nscoring = {\n    'accuracy': 'accuracy',\n    'precision': 'precision',\n    'recall': 'recall',\n    'specificity': make_scorer(specificity_score),  # Include specificity in the scoring dictionary\n    'roc_auc': 'roc_auc'\n}\n\n# Perform cross-validation and retain the models for feature importance\ncv_results = cross_validate(forest_model_nz, X_nz, y_nz, cv=cv, scoring=scoring, return_estimator=True)\n\n# Collect predictions for confusion matrix\ny_pred = cross_val_predict(forest_model_nz, X_nz, y_nz, cv=cv)\n\n# Compute the confusion matrix\ncm = confusion_matrix(y_nz, y_pred)\ncm_display = ConfusionMatrixDisplay(confusion_matrix=cm)\n\n# Printing metrics\nprint(f\"ROC-AUC across {k} folds: {np.mean(cv_results['test_roc_auc']):.2f} ± {np.std(cv_results['test_roc_auc']):.2f}\")\nfor metric in scoring.keys():\n    print(f\"{metric.capitalize()} across {k} folds: {np.mean(cv_results['test_' + metric]):.2f} ± {np.std(cv_results['test_' + metric]):.2f}\")","metadata":{"execution":{"iopub.status.busy":"2024-06-26T20:41:00.047476Z","iopub.execute_input":"2024-06-26T20:41:00.047902Z","iopub.status.idle":"2024-06-26T20:41:04.599247Z","shell.execute_reply.started":"2024-06-26T20:41:00.047870Z","shell.execute_reply":"2024-06-26T20:41:04.597809Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### XGBoost","metadata":{}},{"cell_type":"code","source":"# Initialize the XGBoost model\nxgb_model_nz = XGBClassifier(use_label_encoder=False, eval_metric='logloss')\n\n# Define the number of folds for cross-validation\nk = 5  # Number of folds. k=5 or k=10 is often recommended\ncv = StratifiedKFold(n_splits=k, shuffle=True, random_state=42)\n\n# Specify the parameter grid to search\nparam_dist = {\n    'n_estimators': [100, 200, 300, 400],\n    'max_depth': [3, 5, 7, 10],  # Typical values for depth in XGBoost\n    'learning_rate': [0.01, 0.1, 0.2, 0.3],  # Learning rate or eta\n    'subsample': [0.5, 0.75, 1],  # Subsample ratio of the training instances\n    'colsample_bytree': [0.5, 0.7, 1],  # Subsample ratio of columns when constructing each tree\n    'gamma': [0, 0.1, 0.2, 0.3],  # Minimum loss reduction required to make a further partition\n    'reg_lambda': [1, 2, 3],  # L2 regularization term on weights\n    'reg_alpha': [0, 0.1, 0.2]  # L1 regularization term on weights\n}\n\n# Define different scoring metrics\nscoring = {\n    'accuracy': 'accuracy',\n    'precision': make_scorer(precision_score),\n    'recall': make_scorer(recall_score),\n    'specificity': make_scorer(specificity_score),\n    'roc_auc': 'roc_auc'\n}\n\n# Set up the randomized search with cross-validation\nrandom_search = RandomizedSearchCV(\n    estimator=xgb_model_nz,\n    param_distributions=param_dist,\n    n_iter=100,  # Number of parameter settings sampled\n    scoring='accuracy',  # Can be changed according to what metric you care about\n    cv=cv,\n    verbose=1,\n    random_state=42,\n    n_jobs=-1  # Use all available cores\n)\n\n# Fit RandomizedSearchCV to the data\nrandom_search.fit(X_nz, y_nz)\n\n# Print the best parameters and the corresponding score\nprint(\"Best parameters found: \", random_search.best_params_)\nprint(\"Best accuracy found: \", random_search.best_score_)","metadata":{"execution":{"iopub.status.busy":"2024-06-26T20:41:04.600556Z","iopub.execute_input":"2024-06-26T20:41:04.600945Z","iopub.status.idle":"2024-06-26T20:41:27.370058Z","shell.execute_reply.started":"2024-06-26T20:41:04.600885Z","shell.execute_reply":"2024-06-26T20:41:27.369117Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Assuming X_nz and y_nz are your feature matrix and target vector\n\n# Initialize the XGBoost model with relevant hyperparameters\nxgb_model_nz = XGBClassifier(\n    n_estimators=300,\n    max_depth=10,\n    learning_rate=0.3,\n    subsample=0.8,\n    colsample_bytree=0.5,\n    gamma=0.3,\n    reg_lambda=3,\n    reg_alpha=0.1,\n    use_label_encoder=False,\n    eval_metric='logloss'\n)\n\n# Define the number of folds for cross-validation\nk = 5  # Number of folds\ncv = StratifiedKFold(n_splits=k, shuffle=True, random_state=42)\n\n# Define scoring metrics\nscoring = {\n    'accuracy': 'accuracy',\n    'precision': make_scorer(precision_score),\n    'recall': make_scorer(recall_score),\n    'specificity': make_scorer(specificity_score),\n    'roc_auc': 'roc_auc'\n}\n\n# Compute the correlation matrix\ncorrelation_matrix = X_nz.corr()\n\n# Plot the correlation matrix heatmap\nplt.figure(figsize=(12, 10))\nsns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', vmin=-1, vmax=1)\nplt.title('Correlation Matrix Heatmap New Zealand')\nplt.show()\n\n# Perform cross-validation and return estimators\ncv_results = cross_validate(xgb_model_nz, X_nz, y_nz, cv=cv, scoring=scoring, return_estimator=True)\n\n# Collect predictions for the confusion matrix\ny_pred = cross_val_predict(xgb_model_nz, X_nz, y_nz, cv=cv)\n\n# Compute the confusion matrix\ncm = confusion_matrix(y_nz, y_pred)\ncm_display = ConfusionMatrixDisplay(confusion_matrix=cm)\n\n# Print metrics\nprint(f\"ROC-AUC across {k} folds: {np.mean(cv_results['test_roc_auc']):.2f} ± {np.std(cv_results['test_roc_auc']):.2f}\")\nfor metric in ['test_accuracy', 'test_precision', 'test_recall', 'test_specificity', 'test_roc_auc']:\n    print(f\"{metric.capitalize()} across {k} folds: {np.mean(cv_results[metric]):.2f} ± {np.std(cv_results[metric]):.2f}\")\n\n# Collect all feature importances\nfeature_importances = np.zeros(X_nz.shape[1])\nfor estimator in cv_results['estimator']:\n    feature_importances += estimator.feature_importances_\n\n# Average feature importances\nfeature_importances /= k\n\nfeatures = X_nz.columns\n\n# Print feature importances in order\nprint(\"Feature Importances:\")\nsorted_indices = np.argsort(feature_importances)[::-1]  # Sort indices in descending order of importance\nfor i in sorted_indices:\n    print(f\"{features[i]}: {feature_importances[i]}\")\n\n# Plot feature importances\nindices = np.argsort(feature_importances)\nplt.figure(figsize=(10, 8))\nplt.title('Feature Importances')\nplt.barh(range(len(indices)), feature_importances[indices], color='b', align='center')\nplt.yticks(range(len(indices)), [features[i] for i in indices])\nplt.xlabel('Relative Importance')\nplt.show()\n\n# Plot the confusion matrix\nplt.figure()\ncm_display.plot(cmap=plt.cm.Blues)\nplt.title('Confusion Matrix')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-06-26T20:41:27.371636Z","iopub.execute_input":"2024-06-26T20:41:27.372231Z","iopub.status.idle":"2024-06-26T20:41:30.041745Z","shell.execute_reply.started":"2024-06-26T20:41:27.372198Z","shell.execute_reply":"2024-06-26T20:41:30.040436Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### Recursive Feature Elimination","metadata":{}},{"cell_type":"code","source":"# Initialize the XGBoost model with relevant hyperparameters\nxgb_model_nz = XGBClassifier(\n    n_estimators=300,\n    max_depth=10,\n    learning_rate=0.3,\n    subsample=0.8,\n    colsample_bytree=0.5,\n    gamma=0.3,\n    reg_lambda=3,\n    use_label_encoder=False,\n    eval_metric='logloss'\n)\n\n# Define the number of folds for cross-validation\nk = 5  # Number of folds\ncv = StratifiedKFold(n_splits=k, shuffle=True, random_state=42)\n\n# Define different scoring metrics\nscoring = {\n    'sensitivity': 'recall',\n    'specificity': make_scorer(specificity_score),\n    'balanced_accuracy': make_scorer(balanced_accuracy_score),\n    'roc_auc': 'roc_auc'  # Adding AUROC\n}\n\n# Initialize lists to store metrics for each number of features\nmetrics_history = {\n    'sensitivity': [],\n    'specificity': [],\n    'balanced_accuracy': [],\n    'roc_auc': []  # Adding AUROC to history\n}\n\nnum_features = X_nz.shape[1]\nfeatures_list = X_nz.columns.tolist()  # Store initial full feature list\n\n# Perform RFE with cross-validation and track metrics\nfor i in range(num_features, 0, -1):\n    rfe = RFE(estimator=xgb_model_nz, n_features_to_select=i, step=1)\n    rfe.fit(X_nz, y_nz)\n    \n    # Current set of selected features\n    current_features = list(X_nz.columns[rfe.support_])\n    print(f\"Features retained ({i}): {current_features}\")\n    \n    # Evaluate metrics for the selected features\n    cv_results = cross_validate(rfe.estimator_, rfe.transform(X_nz), y_nz, cv=cv, scoring=scoring)\n    \n    # Store results for plotting\n    for metric in ['sensitivity', 'specificity', 'balanced_accuracy']:  # Excluding AUROC from the plot\n        mean_score = cv_results[f'test_{metric}'].mean()\n        std_score = cv_results[f'test_{metric}'].std()\n        metrics_history[metric].append(mean_score)\n        print(f\"{metric.capitalize()} with {i} features: {mean_score:.2f} ± {std_score:.2f}\")\n    \n    # Also print AUROC separately\n    mean_score = cv_results['test_roc_auc'].mean()\n    std_score = cv_results['test_roc_auc'].std()\n    metrics_history['roc_auc'].append(mean_score)\n    print(f\"ROC-AUC with {i} features: {mean_score:.2f} ± {std_score:.2f}\")\n\n# Plotting the metrics over the number of features (excluding AUROC)\nplt.figure(figsize=(12, 8))\nfeature_counts = list(range(num_features, 0, -1))\nfor metric, values in metrics_history.items():\n    if metric != 'roc_auc':  # Exclude AUROC from the plot\n        plt.plot(feature_counts, values, marker='o', linestyle='-', label=metric.capitalize())\n\nplt.title('New Zealand-Trained Model Performance Across Feature Counts')\nplt.xlabel('Number of Features')\nplt.ylabel('Model Performance')\nplt.legend()\n# plt.gca().invert_xaxis()  # Optional: Invert x-axis to show decreasing number of features\nplt.grid(True)\n# Save the plot to /kaggle/working directory\nplt.savefig('/kaggle/working/model_performance_across_feature_counts_nz.png')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-06-26T20:41:30.043142Z","iopub.execute_input":"2024-06-26T20:41:30.043480Z","iopub.status.idle":"2024-06-26T20:41:47.174238Z","shell.execute_reply.started":"2024-06-26T20:41:30.043450Z","shell.execute_reply":"2024-06-26T20:41:47.172896Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Saudi Dataset","metadata":{}},{"cell_type":"markdown","source":"### Decision Tree","metadata":{}},{"cell_type":"code","source":"# Define the Decision Tree model\ntree_model_saudi_paramSearch = DecisionTreeClassifier()\n\n# Specify the parameter grid to search\nparam_dist = {\n    'criterion': ['gini', 'entropy'],\n    'max_depth': [10, 20, 30, 40, 50], # explored range 10 to 50\n    'min_samples_split': [2, 5, 10],\n    'min_samples_leaf': [1, 2, 4],\n    'max_features': [None, 'sqrt', 'log2']\n}\n\n# Define the number of folds for cross-validation\ncv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n\n# Set up the randomized search with cross-validation\nrandom_search = RandomizedSearchCV(\n    estimator=tree_model_saudi_paramSearch,\n    param_distributions=param_dist,\n    n_iter=100,  # Number of parameter settings sampled\n    scoring='accuracy',  # Can be changed according to what metric you care about\n    cv=cv,\n    verbose=1,\n    random_state=42,\n    n_jobs=-1  # Use all available cores\n)\n\n# Fit RandomizedSearchCV to the data\nrandom_search.fit(X_saudi, y_saudi)\n\n# Print the best parameters and the corresponding score\nprint(\"Best parameters found: \", random_search.best_params_)\nprint(\"Best accuracy found: \", random_search.best_score_)\n\n# Optional: Extract the best model and use it for further analysis or validation\nbest_tree_model = random_search.best_estimator_","metadata":{"execution":{"iopub.status.busy":"2024-06-26T20:41:47.176163Z","iopub.execute_input":"2024-06-26T20:41:47.176599Z","iopub.status.idle":"2024-06-26T20:41:48.855530Z","shell.execute_reply.started":"2024-06-26T20:41:47.176562Z","shell.execute_reply":"2024-06-26T20:41:48.853937Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Initialize the Decision Tree model\ntree_model_saudi = DecisionTreeClassifier(min_samples_split=5, min_samples_leaf=1, max_features=None, max_depth=50, criterion='entropy')\n\n# Define the number of folds for cross-validation\nk = 5  # Number of folds\ncv = StratifiedKFold(n_splits=k, shuffle=True, random_state=42)\n\n# Define different scoring metrics, including specificity\nscoring = {\n    'accuracy': 'accuracy',\n    'precision': 'precision',\n    'recall': 'recall',\n    'specificity': make_scorer(specificity_score),\n    'roc_auc': 'roc_auc'\n}\n\n# Perform cross-validation\ncv_results = cross_validate(tree_model_saudi, X_saudi, y_saudi, cv=cv, scoring=scoring, return_estimator=True)\n\n# Collect predictions for the confusion matrix\ny_pred = cross_val_predict(tree_model_saudi, X_saudi, y_saudi, cv=cv)\n\n# Compute the confusion matrix\ncm = confusion_matrix(y_saudi, y_pred)\ncm_display = ConfusionMatrixDisplay(confusion_matrix=cm)\n\n# Print metrics\nprint(f\"ROC-AUC across {k} folds: {np.mean(cv_results['test_roc_auc']):.2f} ± {np.std(cv_results['test_roc_auc']):.2f}\")\nfor metric in ['accuracy', 'precision', 'recall', 'specificity', 'roc_auc']:  # Remove the redundant 'test_' from the list items\n    mean_value = np.mean(cv_results[f'test_{metric}'])\n    std_value = np.std(cv_results[f'test_{metric}'])\n    print(f\"{metric.capitalize()} across {k} folds: {mean_value:.2f} ± {std_value:.2f}\")","metadata":{"execution":{"iopub.status.busy":"2024-06-26T20:41:48.857562Z","iopub.execute_input":"2024-06-26T20:41:48.858055Z","iopub.status.idle":"2024-06-26T20:41:49.019825Z","shell.execute_reply.started":"2024-06-26T20:41:48.858014Z","shell.execute_reply":"2024-06-26T20:41:49.018402Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Random Forest","metadata":{}},{"cell_type":"code","source":"# Initialize the Random Forest model\nforest_model_saudi = RandomForestClassifier()\n\n# Define the number of folds for cross-validation\nk = 5  # Number of folds. k=5 or k=10 is often recommended\ncv = StratifiedKFold(n_splits=k, shuffle=True, random_state=42)\n\n# Specify the parameter grid to search\nparam_dist = {\n    'n_estimators': [50, 75, 100, 125, 150, 175],  # Tested 50 to 400\n    'criterion': ['gini', 'entropy'],\n    'max_depth': [None, 5, 10, 15], # Tested none to 5 to 50\n    'min_samples_split': [2, 5, 10],\n    'min_samples_leaf': [1, 2, 3], # Tested 1 to 4\n    'max_features': ['sqrt', 'log2'],  # Options for the number of features to consider when looking for the best split\n    'bootstrap': [True, False]  # Method for sampling data points (with or without replacement)\n}\n\n# Define different scoring metrics\nscoring = {\n    'accuracy': make_scorer(accuracy_score),\n    'precision': make_scorer(precision_score),\n    'recall': make_scorer(recall_score),\n    'roc_auc': 'roc_auc'\n}\n\n# Set up the randomized search with cross-validation\nrandom_search = RandomizedSearchCV(\n    estimator=forest_model_saudi,\n    param_distributions=param_dist,\n    n_iter=100,  # Number of parameter settings sampled\n    scoring='accuracy',  # Can be changed according to what metric you care about\n    cv=cv,\n    verbose=1,\n    random_state=42,\n    n_jobs=-1  # Use all available cores\n)\n\n# Fit RandomizedSearchCV to the data\nrandom_search.fit(X_saudi, y_saudi)\n\n# Print the best parameters and the corresponding score\nprint(\"Best parameters found: \", random_search.best_params_)\nprint(\"Best accuracy found: \", random_search.best_score_)","metadata":{"execution":{"iopub.status.busy":"2024-06-26T20:41:49.021456Z","iopub.execute_input":"2024-06-26T20:41:49.021852Z","iopub.status.idle":"2024-06-26T20:42:34.077090Z","shell.execute_reply.started":"2024-06-26T20:41:49.021821Z","shell.execute_reply":"2024-06-26T20:42:34.075595Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Initialize the Random Forest model with specified hyperparameters\nforest_model_saudi = RandomForestClassifier(\n    n_estimators=100,\n    min_samples_split=2,\n    min_samples_leaf=2,\n    max_features='log2',\n    max_depth=10,\n    criterion='entropy',\n    random_state=42,\n    bootstrap=False\n)\n\n# Define the number of folds for cross-validation\nk = 5  # Number of folds\ncv = StratifiedKFold(n_splits=k, shuffle=True, random_state=42)\n\n# Define scoring metrics, including specificity\nscoring = {\n    'accuracy': 'accuracy',\n    'precision': make_scorer(precision_score),\n    'recall': make_scorer(recall_score),\n    'specificity': make_scorer(specificity_score),\n    'roc_auc': 'roc_auc'\n}\n\n# Perform cross-validation and retain the models for feature importance\ncv_results = cross_validate(forest_model_saudi, X_saudi, y_saudi, cv=cv, scoring=scoring, return_estimator=True)\n\n# Collect predictions for confusion matrix\ny_pred = cross_val_predict(forest_model_saudi, X_saudi, y_saudi, cv=cv)\n\n# Compute the confusion matrix\ncm = confusion_matrix(y_saudi, y_pred)\ncm_display = ConfusionMatrixDisplay(confusion_matrix=cm)\n\n# Print metrics\nprint(f\"ROC-AUC across {k} folds: {np.mean(cv_results['test_roc_auc']):.2f} ± {np.std(cv_results['test_roc_auc']):.2f}\")\nfor metric in scoring.keys():\n    if metric != 'roc_auc':  # roc_auc is already formatted in the previous print statement\n        mean_score = np.mean(cv_results[f'test_{metric}'])\n        std_score = np.std(cv_results[f'test_{metric}'])\n        print(f\"{metric.capitalize()} across {k} folds: {mean_score:.2f} ± {std_score:.2f}\")","metadata":{"execution":{"iopub.status.busy":"2024-06-26T20:42:34.079036Z","iopub.execute_input":"2024-06-26T20:42:34.079484Z","iopub.status.idle":"2024-06-26T20:42:36.104855Z","shell.execute_reply.started":"2024-06-26T20:42:34.079451Z","shell.execute_reply":"2024-06-26T20:42:36.103413Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### XGBoost","metadata":{}},{"cell_type":"code","source":"# Initialize the XGBoost model\nxgb_model_saudi = XGBClassifier(use_label_encoder=False, eval_metric='logloss')\n\n# Define the number of folds for cross-validation\nk = 5  # Number of folds. k=5 or k=10 is often recommended\ncv = StratifiedKFold(n_splits=k, shuffle=True, random_state=42)\n\n# Specify the parameter grid to search\nparam_dist = {\n    'n_estimators': [100, 200, 300, 400],\n    'max_depth': [3, 5, 7, 10],  # Typical values for depth in XGBoost\n    'learning_rate': [0.01, 0.1, 0.2, 0.3],  # Learning rate or eta\n    'subsample': [0.5, 0.75, 1],  # Subsample ratio of the training instances\n    'colsample_bytree': [0.5, 0.7, 1],  # Subsample ratio of columns when constructing each tree\n    'gamma': [0, 0.1, 0.2, 0.3],  # Minimum loss reduction required to make a further partition\n    'reg_lambda': [1, 2, 3],  # L2 regularization term on weights\n    'reg_alpha': [0, 0.1, 0.2]  # L1 regularization term on weights\n}\n\n# Define different scoring metrics\nscoring = {\n    'accuracy': 'accuracy',\n    'precision': make_scorer(precision_score),\n    'recall': make_scorer(recall_score),\n    'roc_auc': 'roc_auc'\n}\n\n# Set up the randomized search with cross-validation\nrandom_search = RandomizedSearchCV(\n    estimator=xgb_model_saudi,\n    param_distributions=param_dist,\n    n_iter=100,  # Number of parameter settings sampled\n    scoring='accuracy',  # Can be changed according to what metric you care about\n    cv=cv,\n    verbose=1,\n    random_state=42,\n    n_jobs=-1  # Use all available cores\n)\n\n# Fit RandomizedSearchCV to the data\nrandom_search.fit(X_saudi, y_saudi)\n\n# Print the best parameters and the corresponding score\nprint(\"Best parameters found: \", random_search.best_params_)\nprint(\"Best accuracy found: \", random_search.best_score_)","metadata":{"execution":{"iopub.status.busy":"2024-06-26T20:42:36.106735Z","iopub.execute_input":"2024-06-26T20:42:36.107208Z","iopub.status.idle":"2024-06-26T20:42:54.978207Z","shell.execute_reply.started":"2024-06-26T20:42:36.107174Z","shell.execute_reply":"2024-06-26T20:42:54.976976Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Assuming X_saudi and y_saudi are your feature matrix and target vector\n\n# Initialize the XGBoost model with relevant hyperparameters\nxgb_model_saudi = XGBClassifier(\n    n_estimators=300,\n    max_depth=7,\n    learning_rate=0.1,\n    subsample=0.5,\n    colsample_bytree=0.7,\n    gamma=0,\n    reg_lambda=3,\n    reg_alpha=0.1,\n    use_label_encoder=False,\n    eval_metric='logloss'\n)\n\n# Define the number of folds for cross-validation\nk = 5  # Number of folds\ncv = StratifiedKFold(n_splits=k, shuffle=True, random_state=42)\n\n# Define scoring metrics\nscoring = {\n    'accuracy': 'accuracy',\n    'precision': make_scorer(precision_score),\n    'recall': make_scorer(recall_score),\n    'specificity': make_scorer(specificity_score),\n    'roc_auc': 'roc_auc'\n}\n\n# Compute the correlation matrix\ncorrelation_matrix = X_saudi.corr()\n\n# Plot the correlation matrix heatmap\nplt.figure(figsize=(12, 10))\nsns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', vmin=-1, vmax=1)\nplt.title('Correlation Matrix Heatmap Saudi')\nplt.show()\n\n# Perform cross-validation and return estimators\ncv_results = cross_validate(xgb_model_saudi, X_saudi, y_saudi, cv=cv, scoring=scoring, return_estimator=True)\n\n# Collect predictions for the confusion matrix\ny_pred = cross_val_predict(xgb_model_saudi, X_saudi, y_saudi, cv=cv)\n\n# Compute the confusion matrix\ncm = confusion_matrix(y_saudi, y_pred)\ncm_display = ConfusionMatrixDisplay(confusion_matrix=cm)\n\n# Print metrics\nprint(f\"ROC-AUC across {k} folds: {np.mean(cv_results['test_roc_auc']):.2f} ± {np.std(cv_results['test_roc_auc']):.2f}\")\nfor metric in scoring.keys():\n    if metric != 'roc_auc':  # 'roc_auc' does not require 'test_' prefix in print\n        print(f\"{metric.capitalize()} across {k} folds: {np.mean(cv_results[f'test_{metric}']):.2f} ± {np.std(cv_results[f'test_{metric}']):.2f}\")\n\n# Collect all feature importances\nfeature_importances = np.zeros(X_saudi.shape[1])\nfor estimator in cv_results['estimator']:\n    feature_importances += estimator.feature_importances_\n\n# Average feature importances\nfeature_importances /= k\n\n# Print feature importances in order\nprint(\"Feature Importances:\")\nsorted_indices = np.argsort(feature_importances)[::-1]  # Sort indices in descending order of importance\nfor i in sorted_indices:\n    print(f\"{features[i]}: {feature_importances[i]}\")\n\n# Plot feature importances\nfeatures = X_saudi.columns\nindices = np.argsort(feature_importances)\nplt.figure(figsize=(10, 8))\nplt.title('Feature Importances')\nplt.barh(range(len(indices)), feature_importances[indices], color='b', align='center')\nplt.yticks(range(len(indices)), [features[i] for i in indices])\nplt.xlabel('Relative Importance')\nplt.show()\n\n# Plot the confusion matrix\nplt.figure()\ncm_display.plot(cmap=plt.cm.Blues)\nplt.title('Confusion Matrix')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-06-26T20:42:54.980314Z","iopub.execute_input":"2024-06-26T20:42:54.980970Z","iopub.status.idle":"2024-06-26T20:42:58.164217Z","shell.execute_reply.started":"2024-06-26T20:42:54.980935Z","shell.execute_reply":"2024-06-26T20:42:58.162516Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Recursive Feature Elimination","metadata":{}},{"cell_type":"code","source":"# Initialize the XGBoost model with relevant hyperparameters\nxgb_model_saudi = XGBClassifier(\n    n_estimators=300,\n    max_depth=7,\n    learning_rate=0.1,\n    subsample=0.5,\n    colsample_bytree=0.7,\n    gamma=0,\n    reg_lambda=3,\n    reg_alpha=0.1,\n    use_label_encoder=False,\n    eval_metric='logloss'\n)\n\n# Define the number of folds for cross-validation\nk = 5  # Number of folds\ncv = StratifiedKFold(n_splits=k, shuffle=True, random_state=42)\n\n# Define different scoring metrics\nscoring = {\n    'sensitivity': 'recall',\n    'specificity': make_scorer(specificity_score),\n    'balanced_accuracy': make_scorer(balanced_accuracy_score),\n    'roc_auc': 'roc_auc'  # Adding AUROC\n}\n\n# Initialize lists to store metrics for each number of features\nmetrics_history = {\n    'sensitivity': [],\n    'specificity': [],\n    'balanced_accuracy': [],\n    'roc_auc': []  # Adding AUROC to history\n}\n\nnum_features = X_saudi.shape[1]\nfeatures_list = X_saudi.columns.tolist()  # Store initial full feature list\n\n# Perform RFE with cross-validation and track metrics\nfor i in range(num_features, 0, -1):\n    rfe = RFE(estimator=xgb_model_saudi, n_features_to_select=i, step=1)\n    rfe.fit(X_saudi, y_saudi)\n    \n    # Current set of selected features\n    current_features = list(X_saudi.columns[rfe.support_])\n    print(f\"Features retained ({i}): {current_features}\")\n    \n    # Evaluate metrics for the selected features\n    cv_results = cross_validate(rfe.estimator_, rfe.transform(X_saudi), y_saudi, cv=cv, scoring=scoring)\n    \n    # Store results for plotting\n    for metric in ['sensitivity', 'specificity', 'balanced_accuracy']:  # Excluding AUROC from the plot\n        mean_score = cv_results[f'test_{metric}'].mean()\n        std_score = cv_results[f'test_{metric}'].std()\n        metrics_history[metric].append(mean_score)\n        print(f\"{metric.capitalize()} with {i} features: {mean_score:.2f} ± {std_score:.2f}\")\n    \n    # Also print AUROC separately\n    mean_score = cv_results['test_roc_auc'].mean()\n    std_score = cv_results['test_roc_auc'].std()\n    metrics_history['roc_auc'].append(mean_score)\n    print(f\"ROC-AUC with {i} features: {mean_score:.2f} ± {std_score:.2f}\")\n\n# Plotting the metrics over the number of features (excluding AUROC)\nplt.figure(figsize=(12, 8))\nfeature_counts = list(range(num_features, 0, -1))\nfor metric, values in metrics_history.items():\n    if metric != 'roc_auc':  # Exclude AUROC from the plot\n        plt.plot(feature_counts, values, marker='o', linestyle='-', label=metric.capitalize())\n\nplt.title('Saudi-Trained Model Performance Across Feature Counts')\nplt.xlabel('Number of Features')\nplt.ylabel('Model Performance')\nplt.legend()\n# plt.gca().invert_xaxis()  # Optional: Invert x-axis to show decreasing number of features\nplt.grid(True)\n# Save the plot to /kaggle/working directory\nplt.savefig('/kaggle/working/model_performance_across_feature_counts_saudi.png')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-06-26T20:42:58.166431Z","iopub.execute_input":"2024-06-26T20:42:58.166823Z","iopub.status.idle":"2024-06-26T20:43:17.102549Z","shell.execute_reply.started":"2024-06-26T20:42:58.166792Z","shell.execute_reply":"2024-06-26T20:43:17.100968Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Maximize Recall Full Featured and Best-Performing Model","metadata":{}},{"cell_type":"markdown","source":"## New Zealand Dataset - XGB Model","metadata":{}},{"cell_type":"markdown","source":"### Full Feature Model - train on New Zealand and validate on Saudi","metadata":{}},{"cell_type":"markdown","source":"#### 0.5 Threshold","metadata":{}},{"cell_type":"code","source":"threshold = 0.5\n\nX_saudi = check_and_reorder_columns(X_nz, X_saudi)\n\n# Initialize the XGBoost model with relevant hyperparameters\nxgb_model_nz = XGBClassifier(\n    n_estimators=300,\n    max_depth=10,\n    learning_rate=0.3,\n    subsample=0.8,\n    colsample_bytree=0.5,\n    gamma=0.3,\n    reg_lambda=3,\n    use_label_encoder=False,\n    eval_metric='logloss'\n)\n\n# Train the model on the NZ dataset\nxgb_model_nz.fit(X_nz, y_nz)\n\n# Predict the outcomes on the Saudi dataset using predict_proba\ny_proba_saudi = xgb_model_nz.predict_proba(X_saudi)[:, 1]\ny_pred_saudi = (y_proba_saudi >= threshold).astype(int)\n\n# Evaluate the model\nbalanced_acc = balanced_accuracy_score(y_saudi, y_pred_saudi)\nsensitivity = recall_score(y_saudi, y_pred_saudi)\nspecificity = specificity_score(y_saudi, y_pred_saudi)\nroc_auc = roc_auc_score(y_saudi, y_proba_saudi)\n\n# Compute the standard deviations\nconf_matrix = confusion_matrix(y_saudi, y_pred_saudi)\ntn, fp, fn, tp = conf_matrix.ravel()\ntotal = tn + fp + fn + tp\nbalanced_acc_std = np.sqrt((balanced_acc * (1 - balanced_acc)) / total)\nsens_std = np.sqrt((sensitivity * (1 - sensitivity)) / total)\nspec_std = np.sqrt((specificity * (1 - specificity)) / total)\nroc_auc_std = roc_auc * (1 - roc_auc)\n\n# Print the evaluation results with standard deviations\nprint(f\"Balanced Accuracy: {balanced_acc:.2f} ± {balanced_acc_std:.2f}\")\nprint(f\"Sensitivity: {sensitivity:.2f} ± {sens_std:.2f}\")\nprint(f\"Specificity: {specificity:.2f} ± {spec_std:.2f}\")\nprint(f\"ROC-AUC: {roc_auc:.2f} ± {roc_auc_std:.2f}\")\n\n# Confusion matrix\nprint(\"Confusion Matrix:\")\nprint(conf_matrix)\n\n# Display the confusion matrix graphically\ncm_display = ConfusionMatrixDisplay(confusion_matrix=conf_matrix)\ncm_display.plot(cmap=plt.cm.Blues)\nplt.title('Confusion Matrix')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-06-26T20:43:17.104489Z","iopub.execute_input":"2024-06-26T20:43:17.104970Z","iopub.status.idle":"2024-06-26T20:43:17.563787Z","shell.execute_reply.started":"2024-06-26T20:43:17.104928Z","shell.execute_reply":"2024-06-26T20:43:17.562350Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### 0.3 Threshold","metadata":{}},{"cell_type":"code","source":"threshold = 0.3\n\nX_saudi = check_and_reorder_columns(X_nz, X_saudi)\n\n# Initialize the XGBoost model with relevant hyperparameters\nxgb_model_nz = XGBClassifier(\n    n_estimators=300,\n    max_depth=10,\n    learning_rate=0.3,\n    subsample=0.8,\n    colsample_bytree=0.5,\n    gamma=0.3,\n    reg_lambda=3,\n    use_label_encoder=False,\n    eval_metric='logloss'\n)\n\n# Train the model on the NZ dataset\nxgb_model_nz.fit(X_nz, y_nz)\n\n# Predict the outcomes on the Saudi dataset using predict_proba\ny_proba_saudi = xgb_model_nz.predict_proba(X_saudi)[:, 1]\ny_pred_saudi = (y_proba_saudi >= threshold).astype(int)\n\n# Evaluate the model\nbalanced_acc = balanced_accuracy_score(y_saudi, y_pred_saudi)\nsensitivity = recall_score(y_saudi, y_pred_saudi)\nspecificity = specificity_score(y_saudi, y_pred_saudi)\nroc_auc = roc_auc_score(y_saudi, y_proba_saudi)\n\n# Compute the standard deviations\nconf_matrix = confusion_matrix(y_saudi, y_pred_saudi)\ntn, fp, fn, tp = conf_matrix.ravel()\ntotal = tn + fp + fn + tp\nbalanced_acc_std = np.sqrt((balanced_acc * (1 - balanced_acc)) / total)\nsens_std = np.sqrt((sensitivity * (1 - sensitivity)) / total)\nspec_std = np.sqrt((specificity * (1 - specificity)) / total)\nroc_auc_std = roc_auc * (1 - roc_auc)\n\n# Print the evaluation results with standard deviations\nprint(f\"Balanced Accuracy: {balanced_acc:.2f} ± {balanced_acc_std:.2f}\")\nprint(f\"Sensitivity: {sensitivity:.2f} ± {sens_std:.2f}\")\nprint(f\"Specificity: {specificity:.2f} ± {spec_std:.2f}\")\nprint(f\"ROC-AUC: {roc_auc:.2f} ± {roc_auc_std:.2f}\")\n\n# Confusion matrix\nprint(\"Confusion Matrix:\")\nprint(conf_matrix)\n\n# Display the confusion matrix graphically\ncm_display = ConfusionMatrixDisplay(confusion_matrix=conf_matrix)\ncm_display.plot(cmap=plt.cm.Blues)\nplt.title('Confusion Matrix')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-06-26T20:43:17.565759Z","iopub.execute_input":"2024-06-26T20:43:17.566192Z","iopub.status.idle":"2024-06-26T20:43:18.025871Z","shell.execute_reply.started":"2024-06-26T20:43:17.566160Z","shell.execute_reply":"2024-06-26T20:43:18.024252Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Best-performing model - train on New Zealand and validate on Saudi","metadata":{}},{"cell_type":"markdown","source":"#### 0.5 Threshold","metadata":{}},{"cell_type":"code","source":"threshold = 0.5\n\nX_nz_4features = X_nz.drop(['A1_Score', 'A2_Score', 'A3_Score', 'A4_Score', 'A8_Score', 'A10_Score', 'age_months', 'gender', 'family_pdd'], axis=1)\nX_saudi_4features = X_saudi.drop(['A1_Score', 'A2_Score', 'A3_Score', 'A4_Score', 'A8_Score', 'A10_Score', 'age_months', 'gender', 'family_pdd'], axis=1)\n\nX_saudi_4features = check_and_reorder_columns(X_nz_4features, X_saudi_4features)\n\n# Initialize the XGBoost model with relevant hyperparameters\nxgb_model_nz = XGBClassifier(\n    n_estimators=300,\n    max_depth=10,\n    learning_rate=0.3,\n    subsample=0.8,\n    colsample_bytree=0.5,\n    gamma=0.3,\n    reg_lambda=3,\n    use_label_encoder=False,\n    eval_metric='logloss'\n)\n\n# Train the model on the NZ dataset\nxgb_model_nz.fit(X_nz_4features, y_nz)\n\n# Predict the outcomes on the Saudi dataset using predict_proba\ny_proba_saudi = xgb_model_nz.predict_proba(X_saudi_4features)[:, 1]\ny_pred_saudi = (y_proba_saudi >= threshold).astype(int)\n\n# Evaluate the model\nbalanced_acc = balanced_accuracy_score(y_saudi, y_pred_saudi)\nsensitivity = recall_score(y_saudi, y_pred_saudi)\nspecificity = specificity_score(y_saudi, y_pred_saudi)\nroc_auc = roc_auc_score(y_saudi, y_proba_saudi)  # Ensure y_saudi and predictions are appropriate for ROC calculation\n\n# Compute the standard deviations\nconf_matrix = confusion_matrix(y_saudi, y_pred_saudi)\ntn, fp, fn, tp = conf_matrix.ravel()\ntotal = tn + fp + fn + tp\nbalanced_acc_std = np.sqrt((balanced_acc * (1 - balanced_acc)) / total)\nsens_std = np.sqrt((sensitivity * (1 - sensitivity)) / total)\nspec_std = np.sqrt((specificity * (1 - specificity)) / total)\nroc_auc_std = roc_auc * (1 - roc_auc)\n\n# Print the evaluation results with standard deviations\nprint(f\"Balanced Accuracy: {balanced_acc:.2f} ± {balanced_acc_std:.2f}\")\nprint(f\"Sensitivity: {sensitivity:.2f} ± {sens_std:.2f}\")\nprint(f\"Specificity: {specificity:.2f} ± {spec_std:.2f}\")\nprint(f\"ROC-AUC: {roc_auc:.2f} ± {roc_auc_std:.2f}\")\n\n# Confusion matrix\nprint(\"Confusion Matrix:\")\nprint(conf_matrix)\n\n# Display the confusion matrix graphically\ncm_display = ConfusionMatrixDisplay(confusion_matrix=conf_matrix)\ncm_display.plot(cmap=plt.cm.Blues)\nplt.title('Confusion Matrix')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-06-26T20:43:18.028710Z","iopub.execute_input":"2024-06-26T20:43:18.029248Z","iopub.status.idle":"2024-06-26T20:43:18.454316Z","shell.execute_reply.started":"2024-06-26T20:43:18.029206Z","shell.execute_reply":"2024-06-26T20:43:18.452892Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### O.3 Threshold","metadata":{}},{"cell_type":"code","source":"threshold = 0.3\n\nX_nz_4features = X_nz.drop(['A1_Score', 'A2_Score', 'A3_Score', 'A4_Score', 'A8_Score', 'A10_Score', 'age_months', 'gender', 'family_pdd'], axis=1)\nX_saudi_4features = X_saudi.drop(['A1_Score', 'A2_Score', 'A3_Score', 'A4_Score', 'A8_Score', 'A10_Score', 'age_months', 'gender', 'family_pdd'], axis=1)\n\nX_saudi_4features = check_and_reorder_columns(X_nz_4features, X_saudi_4features)\n\n# Initialize the XGBoost model with relevant hyperparameters\nxgb_model_nz = XGBClassifier(\n    n_estimators=300,\n    max_depth=10,\n    learning_rate=0.3,\n    subsample=0.8,\n    colsample_bytree=0.5,\n    gamma=0.3,\n    reg_lambda=3,\n    use_label_encoder=False,\n    eval_metric='logloss'\n)\n\n# Train the model on the NZ dataset\nxgb_model_nz.fit(X_nz_4features, y_nz)\n\n# Predict the outcomes on the Saudi dataset using predict_proba\ny_proba_saudi = xgb_model_nz.predict_proba(X_saudi_4features)[:, 1]\ny_pred_saudi = (y_proba_saudi >= threshold).astype(int)\n\n# Evaluate the model\nbalanced_acc = balanced_accuracy_score(y_saudi, y_pred_saudi)\nsensitivity = recall_score(y_saudi, y_pred_saudi)\nspecificity = specificity_score(y_saudi, y_pred_saudi)\nroc_auc = roc_auc_score(y_saudi, y_proba_saudi)  # Ensure y_saudi and predictions are appropriate for ROC calculation\n\n# Compute the standard deviations\nconf_matrix = confusion_matrix(y_saudi, y_pred_saudi)\ntn, fp, fn, tp = conf_matrix.ravel()\ntotal = tn + fp + fn + tp\nbalanced_acc_std = np.sqrt((balanced_acc * (1 - balanced_acc)) / total)\nsens_std = np.sqrt((sensitivity * (1 - sensitivity)) / total)\nspec_std = np.sqrt((specificity * (1 - specificity)) / total)\nroc_auc_std = roc_auc * (1 - roc_auc)\n\n# Print the evaluation results with standard deviations\nprint(f\"Balanced Accuracy: {balanced_acc:.2f} ± {balanced_acc_std:.2f}\")\nprint(f\"Sensitivity: {sensitivity:.2f} ± {sens_std:.2f}\")\nprint(f\"Specificity: {specificity:.2f} ± {spec_std:.2f}\")\nprint(f\"ROC-AUC: {roc_auc:.2f} ± {roc_auc_std:.2f}\")\n\n# Confusion matrix\nprint(\"Confusion Matrix:\")\nprint(conf_matrix)\n\n# Display the confusion matrix graphically\ncm_display = ConfusionMatrixDisplay(confusion_matrix=conf_matrix)\ncm_display.plot(cmap=plt.cm.Blues)\nplt.title('Confusion Matrix')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-06-26T20:43:18.456189Z","iopub.execute_input":"2024-06-26T20:43:18.456652Z","iopub.status.idle":"2024-06-26T20:43:18.861309Z","shell.execute_reply.started":"2024-06-26T20:43:18.456613Z","shell.execute_reply":"2024-06-26T20:43:18.859743Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Saudi Dataset - XGB Model","metadata":{}},{"cell_type":"markdown","source":"### Full-feature model - train on Saudi dataset and test on New Zealand","metadata":{}},{"cell_type":"markdown","source":"#### O.5 Threshold","metadata":{}},{"cell_type":"code","source":"threshold = 0.5\n\nX_nz = check_and_reorder_columns(X_saudi, X_nz)\n\n# Initialize the XGBoost model with relevant hyperparameters\nxgb_model_saudi = XGBClassifier(\n    n_estimators=300,\n    max_depth=7,\n    learning_rate=0.1,\n    subsample=0.5,\n    colsample_bytree=0.7,\n    gamma=0,\n    reg_lambda=3,\n    reg_alpha=0.1,\n    use_label_encoder=False,\n    eval_metric='logloss'\n)\n\n# Train the model on the Saudi dataset\nxgb_model_saudi.fit(X_saudi, y_saudi)\n\n# Predict the outcomes on the NZ dataset using predict_proba and threshold\ny_proba_nz = xgb_model_saudi.predict_proba(X_nz)[:, 1]\ny_pred_nz = (y_proba_nz >= threshold).astype(int)  # Using 0.5 as the threshold\n\n# Evaluate the model\nbalanced_acc = balanced_accuracy_score(y_nz, y_pred_nz)\nsensitivity = recall_score(y_nz, y_pred_nz)\nspecificity = specificity_score(y_nz, y_pred_nz)\nroc_auc = roc_auc_score(y_nz, y_proba_nz)  # Directly using the probability scores for ROC AUC\n\n# Compute the standard deviations\nconf_matrix = confusion_matrix(y_nz, y_pred_nz)\ntn, fp, fn, tp = conf_matrix.ravel()\ntotal = tn + fp + fn + tp\nbalanced_acc_std = np.sqrt((balanced_acc * (1 - balanced_acc)) / total)\nsens_std = np.sqrt((sensitivity * (1 - sensitivity)) / total)\nspec_std = np.sqrt((specificity * (1 - specificity)) / total)\nroc_auc_std = roc_auc * (1 - roc_auc)\n\n# Print the evaluation results with standard deviations\nprint(f\"Balanced Accuracy: {balanced_acc:.2f} ± {balanced_acc_std:.2f}\")\nprint(f\"Sensitivity: {sensitivity:.2f} ± {sens_std:.2f}\")\nprint(f\"Specificity: {specificity:.2f} ± {spec_std:.2f}\")\nprint(f\"ROC-AUC: {roc_auc:.2f} ± {roc_auc_std:.2f}\")\n\n# Confusion matrix\nprint(\"Confusion Matrix:\")\nprint(conf_matrix)\n\n# Display the confusion matrix graphically\ncm_display = ConfusionMatrixDisplay(confusion_matrix=conf_matrix)\ncm_display.plot(cmap=plt.cm.Blues)\nplt.title('Confusion Matrix')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-06-26T20:43:18.863414Z","iopub.execute_input":"2024-06-26T20:43:18.863952Z","iopub.status.idle":"2024-06-26T20:43:19.368874Z","shell.execute_reply.started":"2024-06-26T20:43:18.863909Z","shell.execute_reply":"2024-06-26T20:43:19.367759Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### 0.3 Threshold","metadata":{}},{"cell_type":"code","source":"threshold = 0.3\n\nX_nz = check_and_reorder_columns(X_saudi, X_nz)\n\n# Initialize the XGBoost model with relevant hyperparameters\nxgb_model_saudi = XGBClassifier(\n    n_estimators=300,\n    max_depth=7,\n    learning_rate=0.1,\n    subsample=0.5,\n    colsample_bytree=0.7,\n    gamma=0,\n    reg_lambda=3,\n    reg_alpha=0.1,\n    use_label_encoder=False,\n    eval_metric='logloss'\n)\n\n# Train the model on the Saudi dataset\nxgb_model_saudi.fit(X_saudi, y_saudi)\n\n# Predict the outcomes on the NZ dataset using predict_proba and threshold\ny_proba_nz = xgb_model_saudi.predict_proba(X_nz)[:, 1]\ny_pred_nz = (y_proba_nz >= threshold).astype(int)  # Using 0.5 as the threshold\n\n# Evaluate the model\nbalanced_acc = balanced_accuracy_score(y_nz, y_pred_nz)\nsensitivity = recall_score(y_nz, y_pred_nz)\nspecificity = specificity_score(y_nz, y_pred_nz)\nroc_auc = roc_auc_score(y_nz, y_proba_nz)  # Directly using the probability scores for ROC AUC\n\n# Compute the standard deviations\nconf_matrix = confusion_matrix(y_nz, y_pred_nz)\ntn, fp, fn, tp = conf_matrix.ravel()\ntotal = tn + fp + fn + tp\nbalanced_acc_std = np.sqrt((balanced_acc * (1 - balanced_acc)) / total)\nsens_std = np.sqrt((sensitivity * (1 - sensitivity)) / total)\nspec_std = np.sqrt((specificity * (1 - specificity)) / total)\nroc_auc_std = roc_auc * (1 - roc_auc)\n\n# Print the evaluation results with standard deviations\nprint(f\"Balanced Accuracy: {balanced_acc:.2f} ± {balanced_acc_std:.2f}\")\nprint(f\"Sensitivity: {sensitivity:.2f} ± {sens_std:.2f}\")\nprint(f\"Specificity: {specificity:.2f} ± {spec_std:.2f}\")\nprint(f\"ROC-AUC: {roc_auc:.2f} ± {roc_auc_std:.2f}\")\n\n# Confusion matrix\nprint(\"Confusion Matrix:\")\nprint(conf_matrix)\n\n# Display the confusion matrix graphically\ncm_display = ConfusionMatrixDisplay(confusion_matrix=conf_matrix)\ncm_display.plot(cmap=plt.cm.Blues)\nplt.title('Confusion Matrix')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-06-26T20:43:19.370420Z","iopub.execute_input":"2024-06-26T20:43:19.371417Z","iopub.status.idle":"2024-06-26T20:43:20.875168Z","shell.execute_reply.started":"2024-06-26T20:43:19.371376Z","shell.execute_reply":"2024-06-26T20:43:20.873802Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 4-feature model","metadata":{}},{"cell_type":"markdown","source":"#### 0.5 Threshold","metadata":{}},{"cell_type":"code","source":"threshold = 0.5\n\nX_saudi_4features = X_saudi.drop(['A10_Score', 'A7_Score', 'A5_Score', 'A4_Score', 'A3_Score', 'A1_Score', 'family_pdd', 'age_months', 'gender'], axis=1)\nX_nz_4features = X_nz.drop(['A10_Score', 'A7_Score', 'A5_Score', 'A4_Score', 'A3_Score', 'A1_Score', 'family_pdd', 'age_months', 'gender'], axis=1)\n\nX_nz_4features = check_and_reorder_columns(X_saudi_4features, X_nz_4features)\n\n# Initialize the XGBoost model with relevant hyperparameters\nxgb_model_saudi = XGBClassifier(\n    n_estimators=400,\n    max_depth=3,\n    learning_rate=0.01,\n    subsample=1,\n    colsample_bytree=0.7,\n    gamma=0.3,\n    reg_lambda=3,\n    reg_alpha=0,\n    use_label_encoder=False,\n    eval_metric='logloss'\n)\n\n# Train the model on the Saudi dataset\nxgb_model_saudi.fit(X_saudi_4features, y_saudi)\n\n# Predict the outcomes on the NZ dataset using predict_proba and applying a threshold of 0.5\ny_proba_nz = xgb_model_saudi.predict_proba(X_nz_4features)[:, 1]\ny_pred_nz = (y_proba_nz >= threshold).astype(int)  # Using 0.5 as the threshold\n\n# Evaluate the model\nbalanced_acc = balanced_accuracy_score(y_nz, y_pred_nz)\nsensitivity = recall_score(y_nz, y_pred_nz)\nspecificity = specificity_score(y_nz, y_pred_nz)\nroc_auc = roc_auc_score(y_nz, y_proba_nz)  # Using the probabilities for ROC AUC calculation\n\n# Compute the standard deviations\nconf_matrix = confusion_matrix(y_nz, y_pred_nz)\ntn, fp, fn, tp = conf_matrix.ravel()\ntotal = tn + fp + fn + tp\nbalanced_acc_std = np.sqrt((balanced_acc * (1 - balanced_acc)) / total)\nsens_std = np.sqrt((sensitivity * (1 - sensitivity)) / total)\nspec_std = np.sqrt((specificity * (1 - specificity)) / total)\nroc_auc_std = roc_auc * (1 - roc_auc)\n\n# Print the evaluation results with standard deviations\nprint(f\"Balanced Accuracy: {balanced_acc:.2f} ± {balanced_acc_std:.2f}\")\nprint(f\"Sensitivity: {sensitivity:.2f} ± {sens_std:.2f}\")\nprint(f\"Specificity: {specificity:.2f} ± {spec_std:.2f}\")\nprint(f\"ROC-AUC: {roc_auc:.2f} ± {roc_auc_std:.2f}\")\n\n# Confusion matrix\nprint(\"Confusion Matrix:\")\nprint(conf_matrix)\n\n# Display the confusion matrix graphically\ncm_display = ConfusionMatrixDisplay(confusion_matrix=conf_matrix)\ncm_display.plot(cmap=plt.cm.Blues)\nplt.title('Confusion Matrix')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-06-26T20:43:20.877528Z","iopub.execute_input":"2024-06-26T20:43:20.878007Z","iopub.status.idle":"2024-06-26T20:43:21.342461Z","shell.execute_reply.started":"2024-06-26T20:43:20.877968Z","shell.execute_reply":"2024-06-26T20:43:21.341152Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### 0.3 Threshold","metadata":{}},{"cell_type":"code","source":"threshold = 0.3\n\nX_saudi_4features = X_saudi.drop(['A10_Score', 'A7_Score', 'A5_Score', 'A4_Score', 'A3_Score', 'A1_Score', 'family_pdd', 'age_months', 'gender'], axis=1)\nX_nz_4features = X_nz.drop(['A10_Score', 'A7_Score', 'A5_Score', 'A4_Score', 'A3_Score', 'A1_Score', 'family_pdd', 'age_months', 'gender'], axis=1)\n\nX_nz_4features = check_and_reorder_columns(X_saudi_4features, X_nz_4features)\n\n# Initialize the XGBoost model with relevant hyperparameters\nxgb_model_saudi = XGBClassifier(\n    n_estimators=400,\n    max_depth=3,\n    learning_rate=0.01,\n    subsample=1,\n    colsample_bytree=0.7,\n    gamma=0.3,\n    reg_lambda=3,\n    reg_alpha=0,\n    use_label_encoder=False,\n    eval_metric='logloss'\n)\n\n# Train the model on the Saudi dataset\nxgb_model_saudi.fit(X_saudi_4features, y_saudi)\n\n# Predict the outcomes on the NZ dataset using predict_proba and applying a threshold of 0.5\ny_proba_nz = xgb_model_saudi.predict_proba(X_nz_4features)[:, 1]\ny_pred_nz = (y_proba_nz >= threshold).astype(int)  # Using 0.5 as the threshold\n\n# Evaluate the model\nbalanced_acc = balanced_accuracy_score(y_nz, y_pred_nz)\nsensitivity = recall_score(y_nz, y_pred_nz)\nspecificity = specificity_score(y_nz, y_pred_nz)\nroc_auc = roc_auc_score(y_nz, y_proba_nz)  # Using the probabilities for ROC AUC calculation\n\n# Compute the standard deviations\nconf_matrix = confusion_matrix(y_nz, y_pred_nz)\ntn, fp, fn, tp = conf_matrix.ravel()\ntotal = tn + fp + fn + tp\nbalanced_acc_std = np.sqrt((balanced_acc * (1 - balanced_acc)) / total)\nsens_std = np.sqrt((sensitivity * (1 - sensitivity)) / total)\nspec_std = np.sqrt((specificity * (1 - specificity)) / total)\nroc_auc_std = roc_auc * (1 - roc_auc)\n\n# Print the evaluation results with standard deviations\nprint(f\"Balanced Accuracy: {balanced_acc:.2f} ± {balanced_acc_std:.2f}\")\nprint(f\"Sensitivity: {sensitivity:.2f} ± {sens_std:.2f}\")\nprint(f\"Specificity: {specificity:.2f} ± {spec_std:.2f}\")\nprint(f\"ROC-AUC: {roc_auc:.2f} ± {roc_auc_std:.2f}\")\n\n# Confusion matrix\nprint(\"Confusion Matrix:\")\nprint(conf_matrix)\n\n# Display the confusion matrix graphically\ncm_display = ConfusionMatrixDisplay(confusion_matrix=conf_matrix)\ncm_display.plot(cmap=plt.cm.Blues)\nplt.title('Confusion Matrix')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-06-26T20:43:21.344434Z","iopub.execute_input":"2024-06-26T20:43:21.344899Z","iopub.status.idle":"2024-06-26T20:43:22.110558Z","shell.execute_reply.started":"2024-06-26T20:43:21.344863Z","shell.execute_reply":"2024-06-26T20:43:22.109092Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Final Test on Separate Dataset","metadata":{}},{"cell_type":"markdown","source":"## New Zealand Models","metadata":{}},{"cell_type":"markdown","source":"### Full featured model test on Polish dataset","metadata":{}},{"cell_type":"markdown","source":"#### 0.5 Threshold","metadata":{}},{"cell_type":"code","source":"threshold = 0.5\n\nX_polish = check_and_reorder_columns(X_nz, X_polish)\n\n# Initialize the XGBoost model with relevant hyperparameters\nxgb_model_nz = XGBClassifier(\n    n_estimators=300,\n    max_depth=10,\n    learning_rate=0.3,\n    subsample=0.8,\n    colsample_bytree=0.5,\n    gamma=0.3,\n    reg_lambda=3,\n    use_label_encoder=False,\n    eval_metric='logloss'\n)\n\n# Train the model on the NZ dataset\nxgb_model_nz.fit(X_nz, y_nz)\n\n# Predict the probability outcomes on the Polish dataset\ny_proba_polish = xgb_model_nz.predict_proba(X_polish)[:, 1]\ny_pred_polish = (y_proba_polish >= threshold).astype(int)  # Using 0.5 as the classification threshold\n\n# Evaluate the model\nbalanced_acc = balanced_accuracy_score(y_polish, y_pred_polish)\nsensitivity = recall_score(y_polish, y_pred_polish)\nspecificity = specificity_score(y_polish, y_pred_polish)\nroc_auc = roc_auc_score(y_polish, y_proba_polish)  # Using the probability scores for ROC AUC\n\n# Compute the standard deviations\nconf_matrix = confusion_matrix(y_polish, y_pred_polish)\ntn, fp, fn, tp = conf_matrix.ravel()\ntotal = tn + fp + fn + tp\nbalanced_acc_std = np.sqrt((balanced_acc * (1 - balanced_acc)) / total)\nsens_std = np.sqrt((sensitivity * (1 - sensitivity)) / total)\nspec_std = np.sqrt((specificity * (1 - specificity)) / total)\nroc_auc_std = roc_auc * (1 - roc_auc)\n\n# Print the evaluation results with standard deviations\nprint(f\"Balanced Accuracy: {balanced_acc:.2f} ± {balanced_acc_std:.2f}\")\nprint(f\"Sensitivity: {sensitivity:.2f} ± {sens_std:.2f}\")\nprint(f\"Specificity: {specificity:.2f} ± {spec_std:.2f}\")\nprint(f\"ROC-AUC: {roc_auc:.2f} ± {roc_auc_std:.2f}\")\n\n# Confusion matrix\nprint(\"Confusion Matrix:\")\nprint(conf_matrix)\n\n# Display the confusion matrix graphically\ncm_display = ConfusionMatrixDisplay(confusion_matrix=conf_matrix)\ncm_display.plot(cmap=plt.cm.Blues)\nplt.title('Confusion Matrix')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-06-26T20:43:22.112612Z","iopub.execute_input":"2024-06-26T20:43:22.113152Z","iopub.status.idle":"2024-06-26T20:43:22.585413Z","shell.execute_reply.started":"2024-06-26T20:43:22.113107Z","shell.execute_reply":"2024-06-26T20:43:22.584053Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### 0.3 Threshold","metadata":{}},{"cell_type":"code","source":"threshold = 0.3\n\nX_polish = check_and_reorder_columns(X_nz, X_polish)\n\n# Initialize the XGBoost model with relevant hyperparameters\nxgb_model_nz = XGBClassifier(\n    n_estimators=300,\n    max_depth=10,\n    learning_rate=0.3,\n    subsample=0.8,\n    colsample_bytree=0.5,\n    gamma=0.3,\n    reg_lambda=3,\n    use_label_encoder=False,\n    eval_metric='logloss'\n)\n\n# Train the model on the NZ dataset\nxgb_model_nz.fit(X_nz, y_nz)\n\n# Predict the probability outcomes on the Polish dataset\ny_proba_polish = xgb_model_nz.predict_proba(X_polish)[:, 1]\ny_pred_polish = (y_proba_polish >= threshold).astype(int)  # Using 0.3 as the classification threshold\n\n# Evaluate the model\nbalanced_acc = balanced_accuracy_score(y_polish, y_pred_polish)\nsensitivity = recall_score(y_polish, y_pred_polish)\nspecificity = specificity_score(y_polish, y_pred_polish)\nroc_auc = roc_auc_score(y_polish, y_proba_polish)  # Using the probability scores for ROC AUC\n\n# Compute the standard deviations\nconf_matrix = confusion_matrix(y_polish, y_pred_polish)\ntn, fp, fn, tp = conf_matrix.ravel()\ntotal = tn + fp + fn + tp\nbalanced_acc_std = np.sqrt((balanced_acc * (1 - balanced_acc)) / total)\nsens_std = np.sqrt((sensitivity * (1 - sensitivity)) / total)\nspec_std = np.sqrt((specificity * (1 - specificity)) / total)\nroc_auc_std = roc_auc * (1 - roc_auc)\n\n# Print the evaluation results with standard deviations\nprint(f\"Balanced Accuracy: {balanced_acc:.2f} ± {balanced_acc_std:.2f}\")\nprint(f\"Sensitivity: {sensitivity:.2f} ± {sens_std:.2f}\")\nprint(f\"Specificity: {specificity:.2f} ± {spec_std:.2f}\")\nprint(f\"ROC-AUC: {roc_auc:.2f} ± {roc_auc_std:.2f}\")\n\n# Confusion matrix\nprint(\"Confusion Matrix:\")\nprint(conf_matrix)\n\n# Display the confusion matrix graphically\ncm_display = ConfusionMatrixDisplay(confusion_matrix=conf_matrix)\ncm_display.plot(cmap=plt.cm.Blues)\nplt.title('Confusion Matrix')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-06-26T20:43:22.587287Z","iopub.execute_input":"2024-06-26T20:43:22.587838Z","iopub.status.idle":"2024-06-26T20:43:23.049528Z","shell.execute_reply.started":"2024-06-26T20:43:22.587804Z","shell.execute_reply":"2024-06-26T20:43:23.047920Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### 4-features model test on Polish dataset","metadata":{}},{"cell_type":"markdown","source":"#### 0.5 Threshold","metadata":{}},{"cell_type":"code","source":"threshold = 0.5\n\nX_nz_4features = X_nz.drop(['A1_Score', 'A2_Score', 'A3_Score', 'A4_Score', 'A8_Score', 'A10_Score', 'age_months', 'gender', 'family_pdd'], axis=1)\nX_polish_4features = X_polish.drop(['A1_Score', 'A2_Score', 'A3_Score', 'A4_Score', 'A8_Score', 'A10_Score', 'age_months', 'gender', 'family_pdd'], axis=1)\n\nX_polish_4features = check_and_reorder_columns(X_nz_4features, X_polish_4features)\n\n# Initialize the XGBoost model with relevant hyperparameters\nxgb_model_nz = XGBClassifier(\n    n_estimators=300,\n    max_depth=10,\n    learning_rate=0.3,\n    subsample=0.8,\n    colsample_bytree=0.5,\n    gamma=0.3,\n    reg_lambda=3,\n    use_label_encoder=False,\n    eval_metric='logloss'\n)\n\n# Train the model on the NZ dataset\nxgb_model_nz.fit(X_nz_4features, y_nz)\n\n# Predict the probability outcomes on the Polish dataset\ny_proba_polish = xgb_model_nz.predict_proba(X_polish_4features)[:, 1]\ny_pred_polish = (y_proba_polish >= threshold).astype(int)  # Using 0.5 as the classification threshold\n\n# Evaluate the model\nbalanced_acc = balanced_accuracy_score(y_polish, y_pred_polish)\nsensitivity = recall_score(y_polish, y_pred_polish)\nspecificity = specificity_score(y_polish, y_pred_polish)\nroc_auc = roc_auc_score(y_polish, y_proba_polish)  # Using the probability scores for ROC AUC\n\n# Compute the standard deviations\nconf_matrix = confusion_matrix(y_polish, y_pred_polish)\ntn, fp, fn, tp = conf_matrix.ravel()\ntotal = tn + fp + fn + tp\nbalanced_acc_std = np.sqrt((balanced_acc * (1 - balanced_acc)) / total)\nsens_std = np.sqrt((sensitivity * (1 - sensitivity)) / total)\nspec_std = np.sqrt((specificity * (1 - specificity)) / total)\nroc_auc_std = roc_auc * (1 - roc_auc)\n\n# Print the evaluation results with standard deviations\nprint(f\"Balanced Accuracy: {balanced_acc:.2f} ± {balanced_acc_std:.2f}\")\nprint(f\"Sensitivity: {sensitivity:.2f} ± {sens_std:.2f}\")\nprint(f\"Specificity: {specificity:.2f} ± {spec_std:.2f}\")\nprint(f\"ROC-AUC: {roc_auc:.2f} ± {roc_auc_std:.2f}\")\n\n# Confusion matrix\nprint(\"Confusion Matrix:\")\nprint(conf_matrix)\n\n# Display the confusion matrix graphically\ncm_display = ConfusionMatrixDisplay(confusion_matrix=conf_matrix)\ncm_display.plot(cmap=plt.cm.Blues)\nplt.title('Confusion Matrix')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-06-26T20:43:23.051736Z","iopub.execute_input":"2024-06-26T20:43:23.052677Z","iopub.status.idle":"2024-06-26T20:43:23.416897Z","shell.execute_reply.started":"2024-06-26T20:43:23.052633Z","shell.execute_reply":"2024-06-26T20:43:23.415414Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### 0.3 Threshold","metadata":{}},{"cell_type":"code","source":"threshold = 0.3\n\nX_nz_4features = X_nz.drop(['A1_Score', 'A2_Score', 'A3_Score', 'A4_Score', 'A8_Score', 'A10_Score', 'age_months', 'gender', 'family_pdd'], axis=1)\nX_polish_4features = X_polish.drop(['A1_Score', 'A2_Score', 'A3_Score', 'A4_Score', 'A8_Score', 'A10_Score', 'age_months', 'gender', 'family_pdd'], axis=1)\n\nX_polish_4features = check_and_reorder_columns(X_nz_4features, X_polish_4features)\n\n# Initialize the XGBoost model with relevant hyperparameters\nxgb_model_nz = XGBClassifier(\n    n_estimators=300,\n    max_depth=10,\n    learning_rate=0.3,\n    subsample=0.8,\n    colsample_bytree=0.5,\n    gamma=0.3,\n    reg_lambda=3,\n    use_label_encoder=False,\n    eval_metric='logloss'\n)\n\n# Train the model on the NZ dataset\nxgb_model_nz.fit(X_nz_4features, y_nz)\n\n# Predict the probability outcomes on the Polish dataset\ny_proba_polish = xgb_model_nz.predict_proba(X_polish_4features)[:, 1]\ny_pred_polish = (y_proba_polish >= threshold).astype(int)  # Using 0.3 as the classification threshold\n\n# Evaluate the model\nbalanced_acc = balanced_accuracy_score(y_polish, y_pred_polish)\nsensitivity = recall_score(y_polish, y_pred_polish)\nspecificity = specificity_score(y_polish, y_pred_polish)\nroc_auc = roc_auc_score(y_polish, y_proba_polish)  # Using the probability scores for ROC AUC\n\n# Compute the standard deviations\nconf_matrix = confusion_matrix(y_polish, y_pred_polish)\ntn, fp, fn, tp = conf_matrix.ravel()\ntotal = tn + fp + fn + tp\nbalanced_acc_std = np.sqrt((balanced_acc * (1 - balanced_acc)) / total)\nsens_std = np.sqrt((sensitivity * (1 - sensitivity)) / total)\nspec_std = np.sqrt((specificity * (1 - specificity)) / total)\nroc_auc_std = roc_auc * (1 - roc_auc)\n\n# Print the evaluation results with standard deviations\nprint(f\"Balanced Accuracy: {balanced_acc:.2f} ± {balanced_acc_std:.2f}\")\nprint(f\"Sensitivity: {sensitivity:.2f} ± {sens_std:.2f}\")\nprint(f\"Specificity: {specificity:.2f} ± {spec_std:.2f}\")\nprint(f\"ROC-AUC: {roc_auc:.2f} ± {roc_auc_std:.2f}\")\n\n# Confusion matrix\nprint(\"Confusion Matrix:\")\nprint(conf_matrix)\n\n# Display the confusion matrix graphically\ncm_display = ConfusionMatrixDisplay(confusion_matrix=conf_matrix)\ncm_display.plot(cmap=plt.cm.Blues)\nplt.title('Confusion Matrix')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-06-26T20:43:23.419045Z","iopub.execute_input":"2024-06-26T20:43:23.419532Z","iopub.status.idle":"2024-06-26T20:43:23.845930Z","shell.execute_reply.started":"2024-06-26T20:43:23.419492Z","shell.execute_reply":"2024-06-26T20:43:23.844521Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Saudi models","metadata":{}},{"cell_type":"markdown","source":"### Full feature test on Polish dataset","metadata":{}},{"cell_type":"markdown","source":"#### 0.5 Threshold","metadata":{}},{"cell_type":"code","source":"threshold = 0.5\n\nX_saudi = check_and_reorder_columns(X_polish, X_saudi)\n\n# Initialize the XGBoost model with relevant hyperparameters\nxgb_model_saudi = XGBClassifier(\n    n_estimators=300,\n    max_depth=7,\n    learning_rate=0.1,\n    subsample=0.5,\n    colsample_bytree=0.7,\n    gamma=0,\n    reg_lambda=3,\n    reg_alpha=0.1,\n    use_label_encoder=False,\n    eval_metric='logloss'\n)\n\n# Train the model on the Saudi dataset\nxgb_model_saudi.fit(X_saudi, y_saudi)\n\n# Predict the probability outcomes on the Polish dataset\ny_proba_polish = xgb_model_saudi.predict_proba(X_polish)[:, 1]\ny_pred_polish = (y_proba_polish >= threshold).astype(int)  # Convert probabilities to 0 or 1 based on the threshold\n\n# Evaluate the model\nbalanced_acc = balanced_accuracy_score(y_polish, y_pred_polish)\nsensitivity = recall_score(y_polish, y_pred_polish)\nspecificity = specificity_score(y_polish, y_pred_polish)\nroc_auc = roc_auc_score(y_polish, y_proba_polish)  # Using the probability scores for ROC AUC\n\n# Compute the standard deviations\nconf_matrix = confusion_matrix(y_polish, y_pred_polish)\ntn, fp, fn, tp = conf_matrix.ravel()\ntotal = tn + fp + fn + tp\nbalanced_acc_std = np.sqrt((balanced_acc * (1 - balanced_acc)) / total)\nsens_std = np.sqrt((sensitivity * (1 - sensitivity)) / total)\nspec_std = np.sqrt((specificity * (1 - specificity)) / total)\nroc_auc_std = roc_auc * (1 - roc_auc)\n\n# Print the evaluation results with standard deviations\nprint(f\"Balanced Accuracy: {balanced_acc:.2f} ± {balanced_acc_std:.2f}\")\nprint(f\"Sensitivity: {sensitivity:.2f} ± {sens_std:.2f}\")\nprint(f\"Specificity: {specificity:.2f} ± {spec_std:.2f}\")\nprint(f\"ROC-AUC: {roc_auc:.2f} ± {roc_auc_std:.2f}\")\n\n# Confusion matrix\nconf_mat = confusion_matrix(y_polish, y_pred_polish)\nprint(\"Confusion Matrix:\")\nprint(conf_mat)\n\n# Display the confusion matrix graphically\ncm_display = ConfusionMatrixDisplay(confusion_matrix=conf_mat)\ncm_display.plot(cmap=plt.cm.Blues)\nplt.title('Confusion Matrix')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-06-26T20:43:23.847628Z","iopub.execute_input":"2024-06-26T20:43:23.848050Z","iopub.status.idle":"2024-06-26T20:43:24.328922Z","shell.execute_reply.started":"2024-06-26T20:43:23.848017Z","shell.execute_reply":"2024-06-26T20:43:24.327597Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### 0.3 Threshold","metadata":{}},{"cell_type":"code","source":"threshold = 0.3\n\nX_saudi = check_and_reorder_columns(X_polish, X_saudi)\n\n# Initialize the XGBoost model with relevant hyperparameters\nxgb_model_saudi = XGBClassifier(\n    n_estimators=300,\n    max_depth=7,\n    learning_rate=0.1,\n    subsample=0.5,\n    colsample_bytree=0.7,\n    gamma=0,\n    reg_lambda=3,\n    reg_alpha=0.1,\n    use_label_encoder=False,\n    eval_metric='logloss'\n)\n\n# Train the model on the Saudi dataset\nxgb_model_saudi.fit(X_saudi, y_saudi)\n\n# Predict the probability outcomes on the Polish dataset\ny_proba_polish = xgb_model_saudi.predict_proba(X_polish)[:, 1]\ny_pred_polish = (y_proba_polish >= threshold).astype(int)  # Convert probabilities to 0 or 1 based on the threshold\n\n# Evaluate the model\nbalanced_acc = balanced_accuracy_score(y_polish, y_pred_polish)\nsensitivity = recall_score(y_polish, y_pred_polish)\nspecificity = specificity_score(y_polish, y_pred_polish)\nroc_auc = roc_auc_score(y_polish, y_proba_polish)  # Using the probability scores for ROC AUC\n\n# Compute the standard deviations\nconf_matrix = confusion_matrix(y_polish, y_pred_polish)\ntn, fp, fn, tp = conf_matrix.ravel()\ntotal = tn + fp + fn + tp\nbalanced_acc_std = np.sqrt((balanced_acc * (1 - balanced_acc)) / total)\nsens_std = np.sqrt((sensitivity * (1 - sensitivity)) / total)\nspec_std = np.sqrt((specificity * (1 - specificity)) / total)\nroc_auc_std = roc_auc * (1 - roc_auc)\n\n# Print the evaluation results with standard deviations\nprint(f\"Balanced Accuracy: {balanced_acc:.2f} ± {balanced_acc_std:.2f}\")\nprint(f\"Sensitivity: {sensitivity:.2f} ± {sens_std:.2f}\")\nprint(f\"Specificity: {specificity:.2f} ± {spec_std:.2f}\")\nprint(f\"ROC-AUC: {roc_auc:.2f} ± {roc_auc_std:.2f}\")\n\n# Confusion matrix\nconf_mat = confusion_matrix(y_polish, y_pred_polish)\nprint(\"Confusion Matrix:\")\nprint(conf_mat)\n\n# Display the confusion matrix graphically\ncm_display = ConfusionMatrixDisplay(confusion_matrix=conf_mat)\ncm_display.plot(cmap=plt.cm.Blues)\nplt.title('Confusion Matrix')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-06-26T20:43:24.330552Z","iopub.execute_input":"2024-06-26T20:43:24.331026Z","iopub.status.idle":"2024-06-26T20:43:24.809432Z","shell.execute_reply.started":"2024-06-26T20:43:24.330984Z","shell.execute_reply":"2024-06-26T20:43:24.808035Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"###  4 Feature Model on Saudi Dataset","metadata":{}},{"cell_type":"code","source":"threshold = 0.5\n\n# Drop age_months, gender, and family_pdd features from both datasets\nX_saudi_4features = X_saudi.drop(['A10_Score', 'A7_Score', 'A5_Score', 'A4_Score', 'A3_Score', 'A1_Score', 'family_pdd', 'age_months', 'gender'], axis=1)\nX_polish_4features = X_polish.drop(['A10_Score', 'A7_Score', 'A5_Score', 'A4_Score', 'A3_Score', 'A1_Score', 'family_pdd', 'age_months', 'gender'], axis=1)\n\n# Reorder columns in X_saudi dataset\nX_saudi_4features = check_and_reorder_columns(X_polish_4features, X_saudi_4features)\n\n# Initialize the XGBoost model with relevant hyperparameters\nxgb_model_saudi = XGBClassifier(\n    n_estimators=300,\n    max_depth=7,\n    learning_rate=0.1,\n    subsample=0.5,\n    colsample_bytree=0.7,\n    gamma=0,\n    reg_lambda=3,\n    reg_alpha=0.1,\n    use_label_encoder=False,\n    eval_metric='logloss'\n)\n\n# Train the model on the Saudi dataset\nxgb_model_saudi.fit(X_saudi_4features, y_saudi)\n\n# Predict the probability outcomes on the Polish dataset\ny_proba_polish = xgb_model_saudi.predict_proba(X_polish_4features)[:, 1]\ny_pred_polish = (y_proba_polish >= threshold).astype(int)  # Convert probabilities to 0 or 1 based on the threshold\n\n# Evaluate the model\nbalanced_acc = balanced_accuracy_score(y_polish, y_pred_polish)\nsensitivity = recall_score(y_polish, y_pred_polish)\nspecificity = specificity_score(y_polish, y_pred_polish)\nroc_auc = roc_auc_score(y_polish, y_proba_polish)  # Using the probability scores for ROC AUC\n\n# Compute the standard deviations\nconf_matrix = confusion_matrix(y_polish, y_pred_polish)\ntn, fp, fn, tp = conf_matrix.ravel()\ntotal = tn + fp + fn + tp\nbalanced_acc_std = np.sqrt((balanced_acc * (1 - balanced_acc)) / total)\nsens_std = np.sqrt((sensitivity * (1 - sensitivity)) / total)\nspec_std = np.sqrt((specificity * (1 - specificity)) / total)\nroc_auc_std = roc_auc * (1 - roc_auc)\n\n# Print the evaluation results with standard deviations\nprint(f\"Balanced Accuracy: {balanced_acc:.2f} ± {balanced_acc_std:.2f}\")\nprint(f\"Sensitivity: {sensitivity:.2f} ± {sens_std:.2f}\")\nprint(f\"Specificity: {specificity:.2f} ± {spec_std:.2f}\")\nprint(f\"ROC-AUC: {roc_auc:.2f} ± {roc_auc_std:.2f}\")\n\n# Confusion matrix\nprint(\"Confusion Matrix:\")\nprint(conf_matrix)\n\n# Display the confusion matrix graphically\ncm_display = ConfusionMatrixDisplay(confusion_matrix=conf_matrix)\ncm_display.plot(cmap=plt.cm.Blues)\nplt.title('Confusion Matrix')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-06-26T20:43:24.811962Z","iopub.execute_input":"2024-06-26T20:43:24.812460Z","iopub.status.idle":"2024-06-26T20:43:25.241619Z","shell.execute_reply.started":"2024-06-26T20:43:24.812419Z","shell.execute_reply":"2024-06-26T20:43:25.240307Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"threshold = 0.3\n\n# Drop specific features from both datasets\nX_saudi_4features = X_saudi.drop(['A10_Score', 'A7_Score', 'A5_Score', 'A4_Score', 'A3_Score', 'A1_Score', 'family_pdd', 'age_months', 'gender'], axis=1)\nX_polish_4features = X_polish.drop(['A10_Score', 'A7_Score', 'A5_Score', 'A4_Score', 'A3_Score', 'A1_Score', 'family_pdd', 'age_months', 'gender'], axis=1)\n\n# Reorder columns in X_saudi dataset\nX_saudi_4features = check_and_reorder_columns(X_polish_4features, X_saudi_4features)\n\n# Initialize the XGBoost model with relevant hyperparameters\nxgb_model_saudi = XGBClassifier(\n    n_estimators=300,\n    max_depth=7,\n    learning_rate=0.1,\n    subsample=0.5,\n    colsample_bytree=0.7,\n    gamma=0,\n    reg_lambda=3,\n    reg_alpha=0.1,\n    use_label_encoder=False,\n    eval_metric='logloss'\n)\n\n# Train the model on the Saudi dataset\nxgb_model_saudi.fit(X_saudi_4features, y_saudi)\n\n# Predict the probability outcomes on the Polish dataset\ny_proba_polish = xgb_model_saudi.predict_proba(X_polish_4features)[:, 1]\ny_pred_polish = (y_proba_polish >= threshold).astype(int)  # Convert probabilities to 0 or 1 based on the threshold\n\n# Evaluate the model\nbalanced_acc = balanced_accuracy_score(y_polish, y_pred_polish)\nsensitivity = recall_score(y_polish, y_pred_polish)\nspecificity = specificity_score(y_polish, y_pred_polish)\nroc_auc = roc_auc_score(y_polish, y_proba_polish)  # Using the probability scores for ROC AUC\n\n# Compute the standard deviations\nconf_matrix = confusion_matrix(y_polish, y_pred_polish)\ntn, fp, fn, tp = conf_matrix.ravel()\ntotal = tn + fp + fn + tp\nbalanced_acc_std = np.sqrt((balanced_acc * (1 - balanced_acc)) / total)\nsens_std = np.sqrt((sensitivity * (1 - sensitivity)) / total)\nspec_std = np.sqrt((specificity * (1 - specificity)) / total)\nroc_auc_std = roc_auc * (1 - roc_auc)\n\n# Print the evaluation results with standard deviations\nprint(f\"Balanced Accuracy: {balanced_acc:.2f} ± {balanced_acc_std:.2f}\")\nprint(f\"Sensitivity: {sensitivity:.2f} ± {sens_std:.2f}\")\nprint(f\"Specificity: {specificity:.2f} ± {spec_std:.2f}\")\nprint(f\"ROC-AUC: {roc_auc:.2f} ± {roc_auc_std:.2f}\")\n\n# Confusion matrix\nprint(\"Confusion Matrix:\")\nprint(conf_matrix)\n\n# Display the confusion matrix graphically\ncm_display = ConfusionMatrixDisplay(confusion_matrix=conf_matrix)\ncm_display.plot(cmap=plt.cm.Blues)\nplt.title('Confusion Matrix')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-06-26T20:43:25.243192Z","iopub.execute_input":"2024-06-26T20:43:25.243547Z","iopub.status.idle":"2024-06-26T20:43:25.677463Z","shell.execute_reply.started":"2024-06-26T20:43:25.243517Z","shell.execute_reply":"2024-06-26T20:43:25.675938Z"},"trusted":true},"outputs":[],"execution_count":null}]}